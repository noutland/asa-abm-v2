[["index.html", "ASA Agent-Based Model v2 Documentation A High-Performance Simulation Framework for Organizational Dynamics Welcome 0.1 Overview 0.2 Key Features 0.3 Documentation Structure 0.4 Quick Example 0.5 Support and Contributing 0.6 License", " ASA Agent-Based Model v2 Documentation A High-Performance Simulation Framework for Organizational Dynamics ASA ABM Development Team 2025-07-10 Welcome This documentation provides a comprehensive guide to the ASA Agent-Based Model v2, a high-performance simulation framework for studying Attraction-Selection-Attrition (ASA) dynamics in organizations. 0.1 Overview The ASA ABM v2 is designed to simulate how organizations evolve over time through the interplay of: Attraction: How individuals are drawn to organizations based on fit Selection: How organizations choose new members Attrition: How and why members leave organizations 0.2 Key Features High Performance: Built on data.table for efficient large-scale simulations Modular Architecture: Easy to extend and customize Comprehensive Metrics: Track organizational dynamics over time Flexible Parameters: Highly configurable simulation scenarios Future-Ready: Designed for network and hierarchical extensions 0.3 Documentation Structure This documentation is organized into the following sections: Getting Started: Installation and quick start guide Theoretical Background: Understanding the ASA framework Architecture Overview: System design and components with architecture decision log User Guide: Running simulations, configuring parameters, and deep metrics analysis ODD Protocol: Formal model specification following the ODD standard API Reference: Detailed function documentation Examples: Practical simulation scenarios and case studies Model Recipe Book: Ready-to-use configurations for common research questions Contributor’s Guide: Step-by-step walkthrough for developers and contributors Quick Reference: Concise parameter and function reference card 0.4 Quick Example # Load the simulation engine source(&quot;simulation/engine.R&quot;) # Run a basic simulation results &lt;- run_asa_simulation( n_steps = 260, initial_size = 100, params = list(growth_rate = 0.02), verbose = TRUE ) # Analyze results summary(results$metrics) 0.5 Support and Contributing Issues: Report bugs or request features on our GitHub repository Contributing: We welcome contributions! See our contributing guide Contact: Reach out to the development team 0.6 License This project is licensed under the MIT License - see the LICENSE file for details. "],["getting-started.html", "Chapter 1 Getting Started 1.1 System Requirements 1.2 Installation 1.3 Quick Start Guide 1.4 File Structure 1.5 Next Steps 1.6 Troubleshooting", " Chapter 1 Getting Started This chapter will help you get up and running with the ASA ABM v2 simulation framework. 1.1 System Requirements 1.1.1 Software Requirements R version 4.0.0 or higher RStudio (recommended for development) Required R packages: data.table (&gt;= 1.14.0) checkmate (for input validation) ggplot2 (for visualization) knitr and rmarkdown (for documentation) 1.1.2 Hardware Recommendations RAM: Minimum 4GB, 8GB+ recommended for large simulations CPU: Multi-core processor for parallel processing capabilities Storage: 1GB free space for simulation outputs 1.2 Installation 1.2.1 Step 1: Clone or Download the Repository # Clone from GitHub (if available) git clone https://github.com/your-repo/asa-abm-v2.git # Or download and extract the ZIP file 1.2.2 Step 2: Install Required Packages # Install required packages install.packages(c(&quot;data.table&quot;, &quot;checkmate&quot;, &quot;ggplot2&quot;, &quot;knitr&quot;, &quot;rmarkdown&quot;, &quot;bookdown&quot;)) # For PDF documentation generation (optional) install.packages(&quot;tinytex&quot;) tinytex::install_tinytex() 1.2.3 Step 3: Verify Installation # Set working directory to the project folder setwd(&quot;path/to/asa_abm_v2&quot;) # Source the simulation engine source(&quot;simulation/engine.R&quot;) # Run a test simulation test_results &lt;- run_asa_simulation(n_steps = 10, initial_size = 10) print(test_results$metrics) 1.3 Quick Start Guide 1.3.1 Basic Simulation Here’s the simplest way to run a simulation: # Load the simulation engine source(&quot;simulation/engine.R&quot;) # Run simulation with default parameters results &lt;- run_asa_simulation( n_steps = 260, # One year (weekly steps) initial_size = 100 # Starting organization size ) # View summary statistics summary(results$metrics) 1.3.2 Customized Simulation To run a simulation with custom parameters: # Define custom parameters my_params &lt;- list( growth_rate = 0.05, # 5% growth per hiring cycle hiring_frequency = 4, # Hire every 4 weeks selection_criteria = &quot;fit&quot;, # Select based on org fit turnover_threshold = -5 # Leave if satisfaction &lt; -5 ) # Run simulation results &lt;- run_asa_simulation( n_steps = 520, initial_size = 50, params = my_params, verbose = TRUE ) 1.3.3 Analyzing Results The simulation returns a list containing: # Access different components results$final_organization # Final state of all agents results$metrics # Time series of organizational metrics results$parameters # Parameters used in simulation # Basic analysis library(ggplot2) # Plot organization size over time ggplot(results$metrics, aes(x = time, y = size)) + geom_line() + labs(title = &quot;Organization Growth&quot;, x = &quot;Time Step&quot;, y = &quot;Number of Employees&quot;) 1.4 File Structure Understanding the project structure: asa_abm_v2/ ├── core/ # Core modules │ ├── organization.R # Organization functions │ ├── agent.R # Agent/applicant functions │ └── interactions.R # Interaction mechanisms ├── simulation/ # Simulation components │ ├── engine.R # Main simulation loop │ ├── hiring.R # Recruitment logic │ └── turnover.R # Attrition logic ├── analysis/ # Analysis tools ├── tests/ # Unit tests ├── docs/ # Documentation ├── data/ # Sample data and outputs └── run_simulation.R # Example script 1.5 Next Steps Now that you have the simulation running: Read Chapter 2 to understand the ASA framework Explore Chapter 4 for detailed parameter explanations Check Chapter 7 for common simulation scenarios See Chapter 6 for function documentation 1.6 Troubleshooting 1.6.1 Common Issues Issue: “could not find function” error # Solution: Ensure you&#39;ve sourced the engine source(&quot;simulation/engine.R&quot;) Issue: Package not found # Solution: Install missing packages install.packages(&quot;package_name&quot;) Issue: Memory errors with large simulations # Solution: Reduce simulation size or increase R memory limit memory.limit(size = 8000) # Windows # Or use: options(java.parameters = &quot;-Xmx8g&quot;) # 8GB 1.6.2 Getting Help Check the FAQ section Review the API Reference Submit issues on GitHub Contact the development team "],["theoretical-background.html", "Chapter 2 Theoretical Background 2.1 The ASA Framework 2.2 Agent Characteristics 2.3 Interaction Dynamics 2.4 Organizational Metrics 2.5 Temporal Dynamics 2.6 Emergent Phenomena 2.7 Model Assumptions 2.8 Extensions and Variations 2.9 References and Further Reading 2.10 Mathematical Notation Summary", " Chapter 2 Theoretical Background This chapter provides the theoretical foundation for the Attraction-Selection-Attrition (ASA) framework and its implementation in this agent-based model. 2.1 The ASA Framework The Attraction-Selection-Attrition (ASA) framework, developed by Benjamin Schneider (1987), explains how organizations naturally evolve toward homogeneity through three interrelated processes: 2.1.1 Attraction Individuals are differentially attracted to organizations based on perceived fit between their personal characteristics and organizational attributes. In our model: - Agents calculate attraction based on: - Identity similarity (homophily preference) - Organizational diversity (diversity preference) - Personality alignment 2.1.2 Selection Organizations preferentially select individuals who fit their criteria and culture. In our model: - Selection can be based on: - Conscientiousness scores - Overall fit metrics - Random selection (baseline) 2.1.3 Attrition Individuals who don’t fit well with the organization are more likely to leave. In our model: - Turnover occurs through: - Satisfaction thresholds - Probabilistic turnover based on satisfaction - Tenure effects 2.2 Agent Characteristics 2.2.1 Personality Traits (Big Five) Each agent possesses five personality dimensions based on the Five-Factor Model: Openness: Creativity, curiosity, and openness to new experiences Conscientiousness: Organization, dependability, and work ethic Extraversion: Sociability, assertiveness, and energy Agreeableness: Cooperation, trust, and helpfulness Emotional Stability: Calmness, resilience, and emotional control These traits are normally distributed (mean = 0, sd = 1) in the population. 2.2.2 Identity Categories Agents belong to discrete identity categories (default: A, B, C, D, E) representing: - Functional backgrounds - Professional identities - Cultural groups - Or any categorical distinction relevant to the simulation 2.2.3 Preferences Two key preferences drive agent behavior: Homophily Preference: Attraction to similar others Diversity Preference: Attraction to organizational variety 2.3 Interaction Dynamics 2.3.1 Interaction Valence Calculation When agents interact, the quality (valence) of the interaction is determined by: Valence = -|ΔExtraversion| + (Conscientiousnessfocal - Extraversionpartner) + Agreeablenessfocal + IdentityBonus + ε Where: - ΔExtraversion: Difference in extraversion (similarity is beneficial) - IdentityBonus: Homophily preference if same identity, diversity preference if different - ε: Random component scaled by emotional stability 2.3.2 Satisfaction Dynamics Agent satisfaction integrates multiple components: Satisfaction = BaseAttraction + InteractionHistory + IdentityFit + DiversityComponent + PersonalityStability 2.4 Organizational Metrics 2.4.1 Identity Diversity We use Shannon entropy to measure identity diversity: H = -Σ(pi × log(pi)) Where pi is the proportion of identity category i. 2.4.2 Organizational Personality The organization’s personality profile is characterized by: - Mean levels of each Big Five trait - Standard deviations indicating personality diversity 2.5 Temporal Dynamics The model operates in discrete time steps, typically representing: - Days, weeks, or months - Configurable based on research needs Key temporal processes: - Hiring cycles: Periodic recruitment and selection - Interaction accumulation: Building relationship history - Tenure effects: Time-dependent behaviors 2.6 Emergent Phenomena The ASA model produces several emergent patterns: Homogenization: Organizations become more similar over time Culture crystallization: Dominant characteristics become reinforced Fit spirals: Good fit → satisfaction → retention → stronger culture Diversity cycles: Tension between homophily and diversity preferences 2.7 Model Assumptions Key assumptions in our implementation: Perfect information: Applicants can assess organizational fit Stable preferences: Agent preferences don’t change Random interactions: Agents interact randomly (can be modified) Linear satisfaction: Components combine additively 2.8 Extensions and Variations The framework supports several extensions: Network structures: Replace random with network-based interactions Multiple organizations: Inter-organizational mobility Dynamic environments: Changing selection criteria Team structures: Nested organizational units 2.9 References and Further Reading Schneider, B. (1987). The people make the place. Personnel Psychology, 40(3), 437-453. Schneider, B., Goldstein, H. W., &amp; Smith, D. B. (1995). The ASA framework: An update. Personnel Psychology, 48(4), 747-773. Harrison, D. A., Price, K. H., &amp; Bell, M. P. (1998). Beyond relational demography: Time and the effects of surface-and deep-level diversity on work group cohesion. Academy of Management Journal, 41(1), 96-107. 2.10 Mathematical Notation Summary Symbol Description N Organization size I Identity categories π Personality traits vector σ Satisfaction score τ Turnover threshold t Time step H Diversity index "],["architecture.html", "Chapter 3 Architecture Overview 3.1 Design Principles 3.2 System Architecture 3.3 Core Modules 3.4 Simulation Modules 3.5 Data Flow 3.6 Performance Optimizations 3.7 Extension Points 3.8 Configuration Management 3.9 Error Handling 3.10 Testing Architecture 3.11 Architecture Decision Log 3.12 Design Philosophy Summary 3.13 Future Architecture Enhancements", " Chapter 3 Architecture Overview This chapter describes the technical architecture of the ASA ABM v2 system, its design principles, and component interactions. 3.1 Design Principles 3.1.1 1. Performance First Built on data.table for maximum performance in R Vectorized operations wherever possible Efficient memory management 3.1.2 2. Modularity Clear separation of concerns Independent, testable components Easy to extend or replace modules 3.1.3 3. Scalability Handles organizations from 10 to 10,000+ agents Configurable detail levels Memory-conscious data structures 3.1.4 4. Extensibility Prepared for network structures Ready for hierarchical organizations Plugin architecture for new features 3.2 System Architecture ┌─────────────────────────────────────────────────────────┐ │ User Interface │ │ (R Scripts, Shiny Apps, etc.) │ └─────────────────────┬───────────────────────────────────┘ │ ┌─────────────────────▼───────────────────────────────────┐ │ Simulation Engine │ │ (simulation/engine.R) │ ├─────────────────────────────────────────────────────────┤ │ • Orchestrates simulation flow │ │ • Manages time steps │ │ • Collects metrics │ │ • Handles I/O │ └─────────┬───────────────────────────────┬───────────────┘ │ │ ┌─────────▼──────────┐ ┌────────▼───────────┐ │ Core Modules │ │ Simulation Modules │ ├────────────────────┤ ├────────────────────┤ │ • organization.R │ │ • hiring.R │ │ • agent.R │ │ • turnover.R │ │ • interactions.R │ │ • (future modules) │ └────────────────────┘ └────────────────────┘ 3.3 Core Modules 3.3.1 organization.R Manages the organization data structure and organizational-level operations. Key Functions: - create_organization(): Initialize organization with agents - calculate_identity_diversity(): Compute diversity metrics - get_organization_summary(): Extract summary statistics Data Structure: Organization &lt;- data.table( agent_id # Unique identifier identity_category # Categorical identity openness # Big Five traits... conscientiousness extraversion agreeableness emotional_stability diversity_preference # Preferences homophily_preference attraction # State variables satisfaction tenure hire_date # Metadata is_active ) 3.3.2 agent.R Handles individual agents and applicant pools. Key Functions: - create_applicant_pool(): Generate potential hires - calculate_applicant_attraction(): Compute org attraction - applicants_to_employees(): Convert hired applicants Applicant Structure: Applicant &lt;- data.table( agent_id identity_category [personality traits] [preferences] attraction application_time ) 3.3.3 interactions.R Manages agent interactions and satisfaction updates. Key Functions: - execute_interactions_vectorized(): Parallel interaction processing - update_satisfaction_vectorized(): Batch satisfaction updates - get_interaction_summary(): Interaction statistics Interaction Structure: Interactions &lt;- data.table( focal_agent partner_agent time_step valence ) 3.4 Simulation Modules 3.4.1 hiring.R Implements recruitment and selection processes. Key Functions: - execute_hiring(): Main hiring process - recruit_applicants(): Generate new applicants - calculate_fit_metrics(): Assess person-organization fit 3.4.2 turnover.R Manages attrition and retention. Key Functions: - execute_turnover(): Process departures - calculate_turnover_probability(): Probabilistic turnover - identify_flight_risks(): Flag at-risk employees 3.5 Data Flow 3.5.1 1. Initialization Phase create_organization() → Initial agents ↓ initialize_interactions() → Empty interaction table ↓ create_applicant_pool() → Initial applicant pool 3.5.2 2. Simulation Loop For each time step: ├─ update_tenure() ├─ execute_interactions_vectorized() ├─ update_satisfaction_vectorized() ├─ execute_turnover() ├─ [If hiring cycle]: │ ├─ recruit_applicants() │ ├─ calculate_applicant_attraction() │ └─ execute_hiring() └─ calculate_step_metrics() 3.5.3 3. Output Phase Collect results → Save metrics → Save snapshots → Generate reports 3.6 Performance Optimizations 3.6.1 Vectorization Strategy Instead of row-by-row operations: # Bad (slow) for(i in 1:nrow(org)) { org[i, satisfaction := calculate_satisfaction(org[i,])] } # Good (fast) org[, satisfaction := base_attraction + interaction_component + identity_fit] 3.6.2 Memory Management Use data.table reference semantics Selective snapshot storage Efficient key indexing 3.6.3 Parallel Processing Preparation Architecture supports future parallelization: - Independent agent calculations - Batch processing design - Minimal shared state 3.7 Extension Points 3.7.1 1. Network Integration # Future: interactions.R execute_network_interactions &lt;- function(org, network, ...) { # Use network structure instead of random pairing } 3.7.2 2. Hierarchical Organizations # Future: organization.R create_hierarchical_organization &lt;- function(n_agents, n_divisions, hierarchy_levels, ...) { # Create nested structure } 3.7.3 3. Custom Selection Strategies # In hiring.R selection_strategies &lt;- list( conscientiousness = function(x) order(-x$conscientiousness), fit = function(x) order(-x$overall_fit), diversity = function(x) custom_diversity_selection(x), # Add new strategies here ) 3.8 Configuration Management 3.8.1 Parameter Structure params &lt;- list( # Organization identity_categories = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;), # Hiring growth_rate = 0.01, hiring_frequency = 12, selection_criteria = &quot;conscientiousness&quot;, # Interactions n_interactions_per_step = 5, interaction_window = 10, # Turnover turnover_type = &quot;threshold&quot;, turnover_threshold = -10, # ... additional parameters ) 3.8.2 Validation All inputs validated using checkmate: assert_count(n_agents, positive = TRUE) assert_character(identity_categories, min.len = 1) assert_number(growth_rate, lower = 0, upper = 1) 3.9 Error Handling 3.9.1 Defensive Programming # Example from hiring.R if (nrow(applicant_pool) == 0) { return(list(organization = org, applicant_pool = applicant_pool)) } 3.9.2 Logging Strategy if (verbose) { message(sprintf(&quot;Time %d: Hired %d new employees&quot;, current_time, n_hired)) } 3.10 Testing Architecture 3.10.1 Unit Test Structure tests/ ├── test_organization.R ├── test_agent.R ├── test_interactions.R ├── test_hiring.R └── test_turnover.R 3.10.2 Integration Tests # Test full simulation pipeline test_that(&quot;simulation runs without errors&quot;, { results &lt;- run_asa_simulation(n_steps = 10, initial_size = 10) expect_s3_class(results$metrics, &quot;data.table&quot;) expect_gt(nrow(results$metrics), 0) }) 3.11 Architecture Decision Log This section documents key architectural decisions, their rationale, and trade-offs considered. 3.11.1 ADR-001: Why data.table? Decision: Use data.table as the primary data structure for agents and organizations. Context: R offers several data frame implementations: base data.frame, tibble, and data.table. Rationale: - Performance: data.table is 10-100x faster for large datasets - Memory efficiency: Reference semantics avoid copying - Syntax: Concise syntax for complex operations - Scalability: Handles millions of agents efficiently Trade-offs: - Steeper learning curve than tidyverse - Less intuitive for R beginners - Non-standard evaluation can be confusing Benchmarks: # Performance comparison (10,000 agents) # Operation data.frame tibble data.table # Filter &amp; group 850ms 420ms 12ms # Join 1200ms 980ms 45ms # Update by ref 2400ms 2100ms 8ms 3.11.2 ADR-002: Functional vs Object-Oriented Design Decision: Use functional programming with immutable data structures (mostly). Context: R supports both functional and OO (S3, S4, R6) paradigms. Rationale: - Simplicity: Functions are easier to test and reason about - Parallelization: Pure functions enable future parallel processing - Debugging: Easier to trace data flow - R idioms: More aligned with R community practices Trade-offs: - No encapsulation of agent state - More verbose for complex state management - Requires discipline to maintain purity Exception: data.table’s reference semantics for performance-critical updates. 3.11.3 ADR-003: Simulation State Management Decision: Pass complete state through functions rather than global variables. Context: Need to track organization, interactions, and metrics across time steps. Rationale: - Testability: Each function can be tested in isolation - Reproducibility: No hidden state affects results - Clarity: Data flow is explicit - Debugging: Can inspect state at any point Implementation: # State flows through functions org &lt;- create_organization(100) org &lt;- execute_interactions(org, step) org &lt;- execute_turnover(org, threshold) # NOT: update_global_org() 3.11.4 ADR-004: Vectorization Strategy Decision: Vectorize all operations where possible, avoid explicit loops. Context: R loops are slow; vectorized operations leverage C implementations. Rationale: - Performance: 50-200x speedup for agent operations - Readability: Express operations on entire populations - R-native: Leverages R’s strengths Example: # Vectorized (fast) org[, satisfaction := satisfaction + rnorm(.N, mean = valence, sd = 0.1)] # Loop-based (slow) for(i in 1:nrow(org)) { org$satisfaction[i] &lt;- org$satisfaction[i] + rnorm(1, valence[i], 0.1) } 3.11.5 ADR-005: Module Boundaries Decision: Separate by domain concepts, not technical layers. Context: Could organize by technical role (data, logic, presentation) or domain. Rationale: - Cohesion: Related functionality stays together - Understanding: Matches mental model of simulation - Extension: Easy to add new organizational concepts Structure: core/ agent.R # All agent-related functions organization.R # All org-related functions simulation/ hiring.R # Complete hiring process turnover.R # Complete turnover process 3.11.6 ADR-006: Metric Calculation Timing Decision: Calculate metrics after each time step, not on-demand. Context: Could calculate metrics lazily when needed or eagerly each step. Rationale: - Consistency: All metrics from same state - Performance: One pass through data per step - History: Complete time series available - Memory trade-off: Stores more data 3.11.7 ADR-007: Parameter Validation Decision: Use checkmate for runtime parameter validation. Context: Could use base R checks, custom validation, or external package. Rationale: - Comprehensive: Rich set of check functions - Performance: Minimal overhead - Messages: Clear error messages for users - Consistency: Standard validation across codebase 3.11.8 ADR-008: Random Number Generation Decision: Use R’s built-in RNG with explicit seed management. Context: Reproducibility requires careful RNG handling. Rationale: - Standard: Works with all R workflows - Reproducible: set.seed() ensures repeatability - Simple: No external dependencies Best Practice: # Always set seed at simulation start set.seed(params$seed %||% 123) # Use vectorized random generation rnorm(n, mean, sd) # Not: replicate(n, rnorm(1, mean, sd)) 3.11.9 ADR-009: Identity Categories Decision: Use character vectors for identity categories, not factors. Context: R traditionally used factors for categorical data. Rationale: - Flexibility: Easy to add new categories - No surprises: Factors can have unexpected behavior - Performance: Character operations are fast in data.table - Simplicity: Fewer type conversions needed 3.11.10 ADR-010: Extension Mechanism Decision: Prepare for extensions through function factories and strategy patterns. Context: Need to support custom hiring strategies, metrics, etc. Rationale: - Open/Closed: Extend without modifying core - User-friendly: Clear extension points - Type-safe: Functions validate at runtime Example: selection_strategies &lt;- list( conscientiousness = function(x) order(-x$conscientiousness), fit = function(x) order(-x$overall_fit), custom = function(x) user_provided_function(x) ) 3.12 Design Philosophy Summary Performance First: Every decision considers large-scale simulations Functional Core: Pure functions with explicit data flow Domain-Driven: Structure mirrors organizational concepts Extension Ready: Clear points for customization R-Idiomatic: Leverages R’s vectorization strengths These decisions create a system that is: - Fast enough for million-agent simulations - Simple enough for research modifications - Robust enough for production use - Clear enough for educational purposes 3.13 Future Architecture Enhancements Event System: Publish-subscribe for simulation events Plugin Architecture: Dynamic module loading Distributed Simulation: Multi-machine support Real-time Visualization: Live simulation monitoring Database Backend: For very large simulations "],["user-guide.html", "Chapter 4 User Guide 4.1 Running Your First Simulation 4.2 Simulation Parameters 4.3 Common Simulation Scenarios 4.4 Analyzing Results 4.5 Saving and Loading Results 4.6 Batch Simulations 4.7 Performance Tips 4.8 Troubleshooting 4.9 Metrics Deep Dive", " Chapter 4 User Guide This chapter provides detailed guidance on running simulations, configuring parameters, and interpreting results. 4.1 Running Your First Simulation 4.1.1 Basic Simulation The simplest way to run a simulation uses all default parameters: # Load the simulation engine source(&quot;simulation/engine.R&quot;) # Run with defaults results &lt;- run_asa_simulation() 4.1.2 Understanding the Output The simulation returns a list with four components: results$final_organization # Final state data.table results$metrics # Time series metrics results$parameters # Parameters used results$organization_snapshots # Periodic snapshots 4.2 Simulation Parameters 4.2.1 Overview of All Parameters Parameter Type Default Description identity_categories character vector c(“A”,“B”,“C”,“D”,“E”) Possible identity categories growth_rate numeric 0.01 Proportion to hire each cycle hiring_frequency integer 12 Steps between hiring cycles selection_criteria character “conscientiousness” How to select hires n_interactions_per_step integer 5 Interactions per agent per step interaction_window integer 10 Steps to consider for satisfaction turnover_threshold numeric -10 Satisfaction threshold for leaving turnover_type character “threshold” Type of turnover model base_turnover_rate numeric 0.05 Base probability of leaving n_new_applicants integer 50 New applicants per hiring cycle applicant_attraction_threshold numeric -0.5 Min attraction to stay in pool max_application_time integer 12 Steps before application expires 4.2.2 Detailed Parameter Guide 4.2.2.1 Identity Categories Controls the types of identities agents can have: # Default categories params &lt;- list(identity_categories = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;)) # Custom categories (e.g., departments) params &lt;- list(identity_categories = c(&quot;Engineering&quot;, &quot;Sales&quot;, &quot;Marketing&quot;, &quot;Operations&quot;)) 4.2.2.2 Growth and Hiring Configure organizational growth: params &lt;- list( growth_rate = 0.02, # 2% growth per cycle hiring_frequency = 4, # Hire every 4 steps n_new_applicants = 100, # Large applicant pool selection_criteria = &quot;fit&quot; # Select based on fit ) Selection criteria options: - \"conscientiousness\": Highest conscientiousness scores - \"fit\": Best person-organization fit - \"random\": Random selection (baseline) 4.2.2.3 Interaction Settings Control how agents interact: params &lt;- list( n_interactions_per_step = 10, # More interactions interaction_window = 20 # Longer memory ) 4.2.2.4 Turnover Configuration Two turnover models available: Threshold Model: params &lt;- list( turnover_type = &quot;threshold&quot;, turnover_threshold = -5 # Leave if satisfaction &lt; -5 ) Probabilistic Model: params &lt;- list( turnover_type = &quot;probabilistic&quot;, base_turnover_rate = 0.10 # 10% base turnover ) 4.3 Common Simulation Scenarios 4.3.1 Scenario 1: High-Growth Startup startup_params &lt;- list( growth_rate = 0.10, # 10% growth per month hiring_frequency = 4, # Weekly hiring selection_criteria = &quot;fit&quot;, # Culture fit important turnover_threshold = -3, # Low tolerance for dissatisfaction n_new_applicants = 200 # Large applicant pool ) results &lt;- run_asa_simulation( n_steps = 260, initial_size = 20, params = startup_params ) 4.3.2 Scenario 2: Stable Corporation corp_params &lt;- list( growth_rate = 0.005, # 0.5% growth per quarter hiring_frequency = 12, # Monthly hiring selection_criteria = &quot;conscientiousness&quot;, turnover_type = &quot;probabilistic&quot;, base_turnover_rate = 0.02 # 2% monthly turnover ) results &lt;- run_asa_simulation( n_steps = 520, initial_size = 500, params = corp_params ) 4.3.3 Scenario 3: Diversity-Focused Organization diversity_params &lt;- list( growth_rate = 0.02, selection_criteria = &quot;random&quot;, # Reduce selection bias n_interactions_per_step = 20, # Increase mixing interaction_window = 30 # Longer relationship building ) # Also modify agent preferences # (Requires custom initialization - see Developer Guide) 4.4 Analyzing Results 4.4.1 Time Series Analysis library(ggplot2) library(dplyr) # Calculate moving averages results$metrics %&gt;% mutate( ma_satisfaction = zoo::rollmean(avg_satisfaction, 10, fill = NA), ma_size = zoo::rollmean(size, 10, fill = NA) ) %&gt;% ggplot(aes(x = time)) + geom_line(aes(y = avg_satisfaction), alpha = 0.3) + geom_line(aes(y = ma_satisfaction), color = &quot;blue&quot;, size = 1) 4.4.2 Identity Dynamics # Extract identity proportions over time identity_props &lt;- results$organization_snapshots %&gt;% lapply(function(snapshot) { snapshot[is_active == TRUE, .N, by = identity_category] %&gt;% mutate(prop = N / sum(N), time = snapshot$time[1]) }) %&gt;% bind_rows() # Plot identity evolution ggplot(identity_props, aes(x = time, y = prop, color = identity_category)) + geom_line(size = 1) + labs(title = &quot;Identity Category Evolution&quot;, y = &quot;Proportion&quot;) 4.4.3 Turnover Analysis # Calculate turnover rates turnover_analysis &lt;- results$metrics %&gt;% mutate( period = floor(time / 12), # Monthly periods employees_start = lag(size, default = 100) ) %&gt;% group_by(period) %&gt;% summarise( turnover_count = sum(employees_start - size + lag(size - employees_start)), avg_size = mean(size), turnover_rate = turnover_count / avg_size ) 4.5 Saving and Loading Results 4.5.1 Saving Simulation Output # Save with automatic file naming save_simulation_results(results, &quot;my_simulation&quot;) # Creates: # - my_simulation_metrics.csv # - my_simulation_params.rds # - my_simulation_final_org.csv # - my_simulation_snapshots.rds (if requested) 4.5.2 Loading Previous Results # Load saved results metrics &lt;- fread(&quot;my_simulation_metrics.csv&quot;) params &lt;- readRDS(&quot;my_simulation_params.rds&quot;) final_org &lt;- fread(&quot;my_simulation_final_org.csv&quot;) # Recreate results object results &lt;- list( metrics = metrics, parameters = params, final_organization = final_org ) 4.6 Batch Simulations 4.6.1 Parameter Sweeps # Define parameter grid param_grid &lt;- expand.grid( growth_rate = c(0.01, 0.02, 0.05), turnover_threshold = c(-10, -5, -2), selection_criteria = c(&quot;conscientiousness&quot;, &quot;fit&quot;, &quot;random&quot;) ) # Run simulations all_results &lt;- list() for(i in 1:nrow(param_grid)) { params &lt;- as.list(param_grid[i,]) results &lt;- run_asa_simulation( n_steps = 260, initial_size = 100, params = params, verbose = FALSE ) all_results[[i]] &lt;- results$metrics %&gt;% mutate( growth_rate = params$growth_rate, turnover_threshold = params$turnover_threshold, selection_criteria = params$selection_criteria, run_id = i ) } # Combine results combined_results &lt;- bind_rows(all_results) 4.6.2 Replication Studies # Run multiple replications n_replications &lt;- 10 replications &lt;- list() for(rep in 1:n_replications) { set.seed(rep) # Different random seed results &lt;- run_asa_simulation( n_steps = 260, initial_size = 100, params = my_params ) replications[[rep]] &lt;- results$metrics %&gt;% mutate(replication = rep) } # Analyze variance across replications bind_rows(replications) %&gt;% group_by(time) %&gt;% summarise( mean_size = mean(size), sd_size = sd(size), mean_satisfaction = mean(avg_satisfaction), sd_satisfaction = sd(avg_satisfaction) ) 4.7 Performance Tips 4.7.1 Memory Management # For large simulations, reduce snapshot frequency results &lt;- run_asa_simulation( n_steps = 1000, initial_size = 5000, params = list( snapshot_frequency = 50 # Only save every 50 steps ) ) # Clear memory between runs rm(results) gc() 4.7.2 Speed Optimization # Reduce interaction frequency for faster runs fast_params &lt;- list( n_interactions_per_step = 2, # Fewer interactions interaction_window = 5 # Shorter memory ) # Profile simulation performance library(profvis) profvis({ results &lt;- run_asa_simulation(n_steps = 100) }) 4.8 Troubleshooting 4.8.1 Common Issues No hiring occurring: - Check growth_rate &gt; 0 - Verify hiring_frequency aligns with n_steps - Ensure applicant pool is not empty Rapid organization collapse: - Increase turnover_threshold (less negative) - Reduce base_turnover_rate - Check satisfaction calculations Unrealistic homogenization: - Increase n_interactions_per_step - Use selection_criteria = \"random\" - Verify diversity preferences 4.8.2 Debugging Tools # Enable detailed logging debug_results &lt;- run_asa_simulation( n_steps = 20, initial_size = 10, verbose = TRUE, params = list(debug = TRUE) ) # Inspect specific time points time_10 &lt;- results$organization_snapshots[[1]] summary(time_10) 4.9 Metrics Deep Dive Understanding the metrics output is crucial for interpreting simulation results. This section provides detailed explanations of each metric, their calculations, and what they reveal about organizational dynamics. 4.9.1 Overview of Metrics The simulation tracks over 20 metrics at each time step, grouped into several categories: Organizational Composition: Size and identity distribution Diversity Indices: Multiple measures of heterogeneity Personality Distributions: Big Five trait statistics Satisfaction Metrics: Employee well-being indicators 4.9.2 Identity and Diversity Metrics 4.9.2.1 Blau’s Index (Default) # Formula: 1 - Σ(p_i^2) # Where p_i is the proportion of category i Range: 0 (homogeneous) to 0.8 (maximum diversity with 5 categories) Interpretation: Probability two randomly selected employees differ in identity Why it matters: Standard I-O psychology metric for categorical diversity Example: 0.75 indicates high diversity; 0.25 indicates one dominant group 4.9.2.2 Shannon Entropy # Formula: -Σ(p_i * log(p_i)) # Where p_i is the proportion of category i Range: 0 (homogeneous) to log(5) ≈ 1.61 (equal distribution) Interpretation: Information-theoretic measure of uncertainty Why it matters: More sensitive to rare categories than Blau’s Example: 1.5 indicates near-equal distribution; 0.5 indicates strong dominance 4.9.2.3 Category Proportions (prop_A through prop_E) Range: 0 to 1 for each category Interpretation: Fraction of employees in each identity category Why it matters: Direct view of organizational composition Patterns to watch: Gradual drift toward homogeneity Sudden shifts after mass turnover Equilibrium distributions 4.9.3 Personality Trait Metrics For each Big Five trait, the simulation tracks: 4.9.3.1 Average Values (avg_openness, etc.) Range: 0 to 1 Interpretation: Mean trait level in the organization Organizational implications: Openness: Innovation potential, change readiness Conscientiousness: Reliability, performance orientation Extraversion: Communication patterns, collaboration Agreeableness: Conflict levels, team cohesion Emotional Stability: Stress resistance, turnover risk 4.9.3.2 Standard Deviations (sd_openness, etc.) Range: 0 to ~0.5 (theoretical max) Interpretation: Trait heterogeneity in the organization Why it matters: Low SD indicates cultural convergence High SD suggests diverse perspectives Zero SD means complete homogenization 4.9.4 Satisfaction Metrics 4.9.4.1 Average Satisfaction (avg_satisfaction) Range: Typically -20 to +20 Interpretation: Overall employee well-being Key thresholds: Above 0: Generally positive environment Below -5: Risk of increased turnover Below -10: Crisis level (default turnover threshold) 4.9.4.2 Satisfaction Standard Deviation (sd_satisfaction) Range: 0 to ~10 Interpretation: Variation in employee experiences Warning signs: High SD with low average: Polarized organization Increasing SD: Growing disparities Very low SD: Possible groupthink 4.9.5 Interpreting Metric Interactions 4.9.5.1 The Diversity-Satisfaction Paradox # Common pattern plot(results$metrics$blau_index, results$metrics$avg_satisfaction) High diversity often correlates with lower initial satisfaction Homophily preferences drive this relationship Long-term benefits may offset short-term costs 4.9.5.2 Personality Convergence Cascade # Track convergence convergence_rate &lt;- diff(results$metrics$sd_conscientiousness) Selection on one trait affects all traits Convergence accelerates over time Can lead to organizational blindspots 4.9.5.3 Turnover Spirals # Identify spiral onset turnover_indicator &lt;- results$metrics$organization_size &lt; lag(results$metrics$organization_size) Low satisfaction → turnover → lower diversity → lower satisfaction Critical to catch early Intervention points: hiring strategy, satisfaction boost 4.9.6 Advanced Metric Analysis 4.9.6.1 Creating Composite Indices # Organizational Health Index results$metrics[, health_index := 0.3 * (avg_satisfaction + 10) / 20 + # Normalized satisfaction 0.3 * blau_index + # Diversity 0.2 * (organization_size / initial_size) + # Growth 0.2 * (1 - sd_satisfaction / 10) # Cohesion ] 4.9.6.2 Detecting Phase Transitions # Find inflection points library(changepoint) cpt_diversity &lt;- cpt.mean(results$metrics$blau_index) plot(cpt_diversity) 4.9.6.3 Metric Stability Analysis # Rolling window stability window &lt;- 26 # Half year results$metrics[, `:=`( diversity_stability = frollapply(blau_index, window, sd), satisfaction_stability = frollapply(avg_satisfaction, window, sd) )] 4.9.7 Visualization Best Practices 4.9.7.1 Multi-Metric Dashboard library(ggplot2) library(patchwork) # Standardize metrics for comparison results$metrics[, `:=`( std_diversity = scale(blau_index), std_satisfaction = scale(avg_satisfaction), std_size = scale(organization_size) )] # Create aligned time series p_combined &lt;- ggplot(results$metrics, aes(x = time_step)) + geom_line(aes(y = std_diversity, color = &quot;Diversity&quot;)) + geom_line(aes(y = std_satisfaction, color = &quot;Satisfaction&quot;)) + geom_line(aes(y = std_size, color = &quot;Size&quot;)) + scale_color_manual(values = c(&quot;Diversity&quot; = &quot;purple&quot;, &quot;Satisfaction&quot; = &quot;green&quot;, &quot;Size&quot; = &quot;blue&quot;)) + labs(title = &quot;Standardized Organizational Metrics&quot;, y = &quot;Standardized Value (z-score)&quot;, color = &quot;Metric&quot;) + theme_minimal() 4.9.7.2 Phase Space Visualization # 3D phase space library(plotly) plot_ly(results$metrics, x = ~blau_index, y = ~avg_satisfaction, z = ~organization_size, type = &quot;scatter3d&quot;, mode = &quot;lines+markers&quot;, color = ~time_step, colors = &quot;Viridis&quot;) 4.9.8 Common Misinterpretations to Avoid Correlation ≠ Causation: High diversity causing low satisfaction may be mediated by homophily preferences Snapshot Bias: Single time points miss dynamics - always examine trajectories Scale Sensitivity: Raw values less meaningful than trends and relative changes Metric Gaming: Optimizing one metric often degrades others Initial Condition Dependence: Early randomness can have lasting effects 4.9.9 Using Metrics for Model Validation Compare simulation metrics to empirical data: # Example validation checks empirical_turnover_rate &lt;- 0.15 # Annual simulated_annual_turnover &lt;- mean(diff(results$metrics$organization_size[seq(1, 260, 52)]) &lt; 0) empirical_diversity &lt;- 0.65 # Blau&#39;s index from survey simulated_diversity_range &lt;- range(results$metrics$blau_index) # Check if empirical values fall within simulated ranges validation_passed &lt;- empirical_diversity &gt;= simulated_diversity_range[1] &amp; empirical_diversity &lt;= simulated_diversity_range[2] "],["odd-protocol.html", "Chapter 5 ODD Protocol 5.1 1. Purpose and Patterns 5.2 2. Entities, State Variables, and Scales 5.3 3. Process Overview and Scheduling 5.4 4. Design Concepts 5.5 5. Initialization 5.6 6. Input Data 5.7 7. Submodels 5.8 References", " Chapter 5 ODD Protocol This chapter presents the ASA ABM v2 following the ODD (Overview, Design concepts, Details) protocol (Grimm et al., 2010, 2020). The ODD protocol provides a standardized way to describe agent-based models. 5.1 1. Purpose and Patterns 5.1.1 1.1 Purpose The purpose of this model is to simulate the Attraction-Selection-Attrition (ASA) processes in organizations to understand: Primary Questions: How do organizations evolve toward homogeneity through ASA processes? What role do individual preferences (homophily vs. diversity) play in organizational composition? How do different selection strategies affect long-term organizational diversity? What are the dynamics of satisfaction and turnover in evolving organizations? Secondary Questions: How does interaction frequency affect organizational culture formation? What is the relationship between personality diversity and organizational stability? How do hiring cycles and growth rates influence organizational evolution? 5.1.2 1.2 Patterns The model aims to reproduce and explain the following patterns observed in organizational research: Organizational Homogenization: Organizations tend to become more homogeneous over time Fit-Satisfaction-Retention Spiral: Better fitting employees are more satisfied and stay longer Diversity-Performance Relationship: Complex relationships between diversity and organizational outcomes Turnover Cascades: Departures can trigger additional turnover through social effects 5.2 2. Entities, State Variables, and Scales 5.2.1 2.1 Entities The model contains three types of entities: Agents (Employees and Applicants) Represent individuals who work in or apply to the organization Possess personality traits, identity, and preferences Can transition from applicant to employee Organization Collection of agents marked as active employees Emergent properties calculated from constituent agents Interactions Pairwise encounters between agents Store history of social experiences 5.2.2 2.2 State Variables 5.2.2.1 Agent-level State Variables Variable Type Range/Values Description agent_id character Unique string Unique identifier identity_category character “A”-“E” (default) Categorical identity openness numeric ~N(0,1) Big Five personality trait conscientiousness numeric ~N(0,1) Big Five personality trait extraversion numeric ~N(0,1) Big Five personality trait agreeableness numeric ~N(0,1) Big Five personality trait emotional_stability numeric ~N(0,1) Big Five personality trait homophily_preference numeric ~N(0,1) Preference for similarity diversity_preference numeric ~N(0,1) Preference for diversity attraction numeric Real Attraction to organization satisfaction numeric Real Current satisfaction level tenure integer 0+ Time steps in organization hire_date integer 0+ Time step when hired is_active logical TRUE/FALSE Currently employed application_time integer 0+ Time as applicant (applicants only) 5.2.2.2 Organization-level Variables (Emergent) Variable Type Description size integer Number of active agents identity_diversity numeric Shannon entropy of identities avg_satisfaction numeric Mean satisfaction of active agents personality_means numeric vector Mean of each Big Five trait personality_sds numeric vector SD of each Big Five trait 5.2.2.3 Global Variables Variable Type Description time integer Current simulation step parameters list Simulation parameters 5.2.3 2.3 Scales Temporal Scale: One time step typically represents one week Simulations typically run for 260-520 steps (1-2 years) Hiring cycles occur every 4-12 steps Organizational Scale: Organizations range from 10 to 10,000+ agents Typical simulations use 100-1,000 agents 5.3 3. Process Overview and Scheduling 5.3.1 3.1 Process Overview Each time step consists of the following processes in order: Update Tenure: Increment tenure for all active agents Execute Interactions: Agents interact with randomly selected partners Update Satisfaction: Calculate new satisfaction based on interactions Execute Turnover: Remove agents below satisfaction threshold Hiring Cycle (periodic): Age applicant pool Recruit new applicants Calculate applicant attraction Filter applicant pool Select and hire new employees Calculate Metrics: Record organizational state 5.3.2 3.2 Scheduling Sequential Processing: Processes execute in the order listed above Synchronous Updates: All agents update simultaneously within each process Discrete Time: All events occur at discrete time steps Conditional Execution: Hiring only occurs at specified intervals 5.4 4. Design Concepts 5.4.1 4.1 Basic Principles The model implements the ASA framework through: - Attraction: Differential attraction based on fit - Selection: Preferential hiring of fitting individuals - Attrition: Satisfaction-based turnover 5.4.2 4.2 Emergence The following properties emerge from individual-level behaviors: - Organizational culture (personality profile) - Identity composition and diversity - Turnover patterns and rates - Social network properties (implicit in interactions) 5.4.3 4.3 Adaptation Agents adapt through: - Satisfaction updates based on experiences - Turnover decisions based on satisfaction - No learning or trait changes (fixed personalities) 5.4.4 4.4 Objectives Agents seek to: - Applicants: Join organizations with high attraction - Employees: Maintain satisfaction above threshold - Organization: Hire best-fitting applicants (implicit) 5.4.5 4.5 Learning No explicit learning in current model. Agents have fixed traits and preferences. 5.4.6 4.6 Prediction Agents implicitly predict: - Applicants assess organizational fit before joining - Employees evaluate satisfaction trends (through threshold mechanism) 5.4.7 4.7 Sensing Agents can sense: - Organizational identity composition (for attraction calculation) - Interaction partner characteristics (during interactions) - Own satisfaction level 5.4.8 4.8 Interaction Direct: Pairwise interactions between agents Indirect: Through organizational composition effects Interaction Selection: Random pairing (extensible to networks) 5.4.9 4.9 Stochasticity Stochastic elements include: - Agent trait initialization (~N(0,1)) - Identity assignment (uniform random) - Interaction partner selection (random) - Interaction valence noise (scaled by emotional stability) - Hiring decisions (when using random selection) 5.4.10 4.10 Collectives The organization represents a collective with emergent properties calculated from member characteristics. 5.4.11 4.11 Observation The model collects: - Time series of organizational metrics - Final organization state - Periodic snapshots (configurable) - Interaction histories 5.5 5. Initialization 5.5.1 5.1 Initial Conditions Default initialization: # Create initial organization initial_size = 100 identity_categories = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;) # Agents initialized with: - Random identities (uniform distribution) - Personality traits ~ N(0,1) - Preferences ~ N(0,1) - Attraction = 0 - Satisfaction = 0 - Tenure = 0 - All marked as active 5.5.2 5.2 Input Data The model can accept: - Custom identity category definitions - Specified initial organization size - Parameter configurations - Random seed for reproducibility 5.6 6. Input Data No external data files required. All agent characteristics generated stochastically during initialization. 5.7 7. Submodels 5.7.1 7.1 Attraction Calculation For Applicants: Attraction = (HomophilyPref × PropSameIdentity) + (DiversityPref × DiversityIndex) 5.7.2 7.2 Interaction Valence When agents i and j interact: Valence_ij = -|Extraversion_i - Extraversion_j| + (Conscientiousness_i - Extraversion_j) + Agreeableness_i + IdentityBonus + ε Where: - IdentityBonus = HomophilyPref_i if same identity, DiversityPref_i if different - ε ~ N(0, |EmotionalStability_i|) 5.7.3 7.3 Satisfaction Update Satisfaction_i = Attraction_i + mean(RecentInteractionValences) + (HomophilyPref_i × PropSameIdentity) + (DiversityPref_i × DiversityIndex) + EmotionalStability_i 5.7.4 7.4 Turnover Decision Threshold Model: if (Satisfaction &lt; TurnoverThreshold) then Leave Probabilistic Model: P(Leave) = BaseTurnoverRate / (1 + exp(Satisfaction × Weight)) 5.7.5 7.5 Hiring Process Rank applicants by criterion (conscientiousness/fit/random) Select top N where N = CurrentSize × GrowthRate Convert selected applicants to employees Add to organization 5.7.6 7.6 Identity Diversity Shannon Entropy: H = -Σ(p_i × log(p_i)) Where p_i is the proportion of identity category i. 5.8 References Grimm, V., Berger, U., Bastiansen, F., Eliassen, S., Ginot, V., Giske, J., … &amp; DeAngelis, D. L. (2006). A standard protocol for describing individual-based and agent-based models. Ecological Modelling, 198(1-2), 115-126. Grimm, V., Berger, U., DeAngelis, D. L., Polhill, J. G., Giske, J., &amp; Railsback, S. F. (2010). The ODD protocol: A review and first update. Ecological Modelling, 221(23), 2760-2768. Grimm, V., Railsback, S. F., Vincenot, C. E., Berger, U., Gallagher, C., DeAngelis, D. L., … &amp; Ayllón, D. (2020). The ODD protocol for describing agent-based and other simulation models: A second update to improve clarity, replication, and structural realism. Journal of Artificial Societies and Social Simulation, 23(2), 7. "],["api-reference.html", "Chapter 6 API Reference 6.1 Core Modules 6.2 Error Handling 6.3 Performance Notes", " Chapter 6 API Reference This chapter provides detailed documentation for all functions in the ASA ABM v2. Functions are organized by module with complete specifications. 6.1 Core Modules 6.1.1 core/organization.R Functions for creating and managing organizations. 6.1.1.1 create_organization() Create an organization data.table with agents. Usage create_organization(n_agents = 100, identity_categories = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;)) Arguments - n_agents: Number of agents to create (default: 100) - identity_categories: Vector of possible identity categories Value Returns a data.table with columns: - agent_id: Unique identifier - identity_category: Agent’s identity group - openness, conscientiousness, extraversion, agreeableness, emotional_stability: Big Five traits - homophily_preference, diversity_preference: Agent preferences - attraction, satisfaction: State variables - tenure, hire_date, is_active: Employment tracking Examples # Create default organization org &lt;- create_organization() # Create with custom identities org &lt;- create_organization( n_agents = 250, identity_categories = c(&quot;Tech&quot;, &quot;Sales&quot;, &quot;Ops&quot;) ) 6.1.1.2 calculate_identity_diversity() Calculate Shannon entropy for identity diversity. Usage calculate_identity_diversity(org) Arguments - org: Organization data.table Value Returns numeric Shannon entropy value (0 = homogeneous, higher = more diverse) 6.1.1.3 calculate_blau_index() Calculate Blau’s Index of heterogeneity for identity categories (I-O psychology standard). Usage calculate_blau_index(org) Arguments - org: Organization data.table Value Returns numeric Blau’s Index (0 = homogeneous, 1 = maximum diversity). Represents the probability that two randomly selected members are from different categories. 6.1.1.4 get_category_proportions() Get proportions of each identity category. Usage get_category_proportions(org) Arguments - org: Organization data.table Value Returns named vector with proportions for each category (A-E) Usage calculate_identity_diversity(org) Arguments - org: Organization data.table Value Numeric Shannon entropy value (0 = homogeneous, higher = more diverse) Examples diversity &lt;- calculate_identity_diversity(org) print(paste(&quot;Diversity index:&quot;, round(diversity, 3))) 6.1.1.5 calculate_personality_averages() Get mean personality traits for active employees. Usage calculate_personality_averages(org) Arguments - org: Organization data.table Value Numeric vector of trait means in order: openness, conscientiousness, extraversion, agreeableness, emotional_stability 6.1.1.6 calculate_personality_variance() Get standard deviations of personality traits. Usage calculate_personality_variance(org) Arguments - org: Organization data.table Value Numeric vector of trait SDs 6.1.1.7 get_organization_size() Count active employees. Usage get_organization_size(org) Arguments - org: Organization data.table Value Integer count of employees where is_active == TRUE 6.1.1.8 calculate_average_satisfaction() Compute mean satisfaction of active employees. Usage calculate_average_satisfaction(org) Arguments - org: Organization data.table Value Numeric mean satisfaction score 6.1.1.9 get_organization_summary() Generate comprehensive organizational metrics. Usage get_organization_summary(org) Arguments - org: Organization data.table Value List containing: - size: Active employee count - identity_diversity: Shannon entropy - avg_satisfaction: Mean satisfaction - avg_tenure: Mean tenure - personality_means: Vector of trait means - personality_sds: Vector of trait SDs - turnover_rate: Proportion inactive 6.1.2 core/agent.R Functions for managing applicant pools. 6.1.2.1 create_applicant_pool() Generate pool of potential applicants. Usage create_applicant_pool(n_applicants = 50, identity_categories = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;)) Arguments - n_applicants: Number of applicants to generate - identity_categories: Possible identity categories Value data.table with applicant information including unique IDs and application_time field Examples # Create standard pool applicants &lt;- create_applicant_pool() # Large pool with custom categories applicants &lt;- create_applicant_pool( n_applicants = 200, identity_categories = c(&quot;Eng&quot;, &quot;Prod&quot;, &quot;Sales&quot;) ) 6.1.2.2 calculate_applicant_attraction() Calculate attraction scores for applicants. Usage calculate_applicant_attraction(applicants, org, diversity_metric = &quot;blau&quot;) Arguments - applicants: Applicant pool data.table - org: Organization data.table - diversity_metric: Character string specifying which diversity metric to use (“blau” or “shannon”, default: “blau”) Value Updated applicants data.table with attraction scores based on identity fit and diversity Examples # Calculate attraction applicants &lt;- calculate_applicant_attraction(applicants, org, diversity_metric = &quot;blau&quot;) # View top attracted applicants top_applicants &lt;- applicants[order(-attraction)][1:10] 6.1.2.3 filter_applicant_pool() Remove applicants below attraction threshold. Usage filter_applicant_pool(applicants, min_attraction = -0.5) Arguments - applicants: Applicant pool data.table - min_attraction: Minimum attraction score to remain Value Filtered applicants data.table 6.1.2.4 age_applicant_pool() Increment application time and remove stale applications. Usage age_applicant_pool(applicants, max_application_time = 12) Arguments - applicants: Applicant pool data.table - max_application_time: Maximum time before removal Value Updated applicants with incremented time and stale applications removed 6.1.2.5 applicants_to_employees() Convert selected applicants to employee records. Usage applicants_to_employees(selected_applicants, hire_time = 0) Arguments - selected_applicants: Applicants to hire - hire_time: Current simulation time Value data.table of new employees with employee-specific fields added 6.1.3 core/interactions.R Functions for agent interactions and satisfaction. 6.1.3.1 initialize_interactions() Create empty interactions tracking table. Usage initialize_interactions(org) Arguments - org: Organization data.table Value Empty data.table with columns: focal_agent, partner_agent, time_step, valence 6.1.3.2 execute_interactions_vectorized() Perform one round of interactions using vectorized operations. Usage execute_interactions_vectorized(org, interactions, time_step, n_interactions = 1) Arguments - org: Organization data.table - interactions: Interaction history table - time_step: Current simulation time - n_interactions: Interactions per agent Value Updated interactions table with new interaction records Details Interaction valence calculated as: valence = -|ΔExtraversion| + (Consc_focal - Extra_partner) + Agree_focal + IdentityBonus + ε Where IdentityBonus depends on homophily/diversity preferences and identity match. 6.1.3.3 update_satisfaction_vectorized() Update all agent satisfaction scores efficiently. Usage update_satisfaction_vectorized(org, interactions, window_size = 10, diversity_metric = &quot;blau&quot;) Arguments - org: Organization data.table - interactions: Interaction history - window_size: Recent time steps to consider - diversity_metric: Character string specifying which diversity metric to use (“blau” or “shannon”, default: “blau”) Value Updated organization with new satisfaction scores 6.1.3.4 get_interaction_summary() Summarize recent interaction patterns. Usage get_interaction_summary(interactions, last_n_steps = 10) Arguments - interactions: Interaction history table - last_n_steps: Number of recent steps to analyze Value List with summary statistics: - total_interactions: Count - avg_valence: Mean interaction quality - sd_valence: Valence standard deviation - n_unique_pairs: Unique interaction pairs 6.1.4 simulation/hiring.R Functions for recruitment and selection. 6.1.4.1 execute_hiring() Main hiring process function. Usage execute_hiring(org, applicant_pool, growth_rate = 0.1, selection_criteria = &quot;conscientiousness&quot;, current_time = 0) Arguments - org: Organization data.table - applicant_pool: Available applicants - growth_rate: Proportion of current size to hire - selection_criteria: “conscientiousness”, “fit”, or “random” - current_time: Current simulation time Value List containing: - organization: Updated with new hires - applicant_pool: Remaining applicants Examples # Hire based on conscientiousness result &lt;- execute_hiring(org, applicants, growth_rate = 0.02) org &lt;- result$organization applicants &lt;- result$applicant_pool # Hire based on fit result &lt;- execute_hiring( org, applicants, selection_criteria = &quot;fit&quot; ) 6.1.4.2 recruit_applicants() Generate new applicants or add to existing pool. Usage recruit_applicants(existing_pool = NULL, n_new_applicants = 50, identity_categories = c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;)) Arguments - existing_pool: Current applicant pool (optional) - n_new_applicants: Number to generate - identity_categories: Possible identities Value Updated applicant pool data.table 6.1.4.3 calculate_fit_metrics() Calculate person-organization fit scores. Usage calculate_fit_metrics(org, applicants) Arguments - org: Organization data.table - applicants: Applicant pool Value Applicants with added fit metrics: - personality_fit: Based on trait distance - preference_fit: Based on preference alignment - overall_fit: Combined fit score 6.1.4.4 get_hiring_stats() Generate hiring statistics. Usage get_hiring_stats(org, time_window = 12) Arguments - org: Organization data.table - time_window: Recent period to analyze Value List of hiring metrics including recent hires, hiring rate, and demographics 6.1.5 simulation/turnover.R Functions for managing attrition. 6.1.5.1 execute_turnover() Remove employees below satisfaction threshold. Usage execute_turnover(org, turnover_threshold = -10, current_time = 0) Arguments - org: Organization data.table - turnover_threshold: Satisfaction threshold - current_time: Current simulation time Value Updated organization with low-satisfaction employees marked inactive 6.1.5.2 calculate_turnover_probability() Compute probabilistic turnover likelihood. Usage calculate_turnover_probability(org, base_turnover_rate = 0.05, satisfaction_weight = 0.1) Arguments - org: Organization data.table - base_turnover_rate: Baseline probability - satisfaction_weight: Impact of satisfaction Value Organization with added turnover_prob column 6.1.5.3 execute_probabilistic_turnover() Execute turnover based on probabilities. Usage execute_probabilistic_turnover(org, current_time = 0) Arguments - org: Organization with turnover probabilities - current_time: Current simulation time Value Updated organization after probabilistic departures 6.1.5.4 update_tenure() Increment tenure for active employees. Usage update_tenure(org, time_increment = 1) Arguments - org: Organization data.table - time_increment: Time units to add Value Organization with updated tenure values 6.1.5.5 get_turnover_stats() Calculate comprehensive turnover metrics. Usage get_turnover_stats(org, time_window = 12) Arguments - org: Organization data.table - time_window: Period to analyze Value List containing: - Turnover counts and rates - Average tenure comparisons - Satisfaction analysis - Identity-specific turnover 6.1.5.6 identify_flight_risks() Flag employees likely to leave. Usage identify_flight_risks(org, risk_threshold = 0.25) Arguments - org: Organization data.table - risk_threshold: Satisfaction percentile threshold Value data.table of at-risk employees sorted by satisfaction 6.1.6 simulation/engine.R Main simulation control functions. 6.1.6.1 run_asa_simulation() Execute complete ASA simulation. Usage run_asa_simulation(n_steps = 260, initial_size = 100, params = list(), verbose = TRUE) Arguments - n_steps: Number of time steps - initial_size: Starting organization size - params: Simulation parameters (see details) - verbose: Print progress messages Parameters List params = list( identity_categories = c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;), growth_rate = 0.01, hiring_frequency = 12, selection_criteria = &quot;conscientiousness&quot;, n_interactions_per_step = 5, interaction_window = 10, turnover_threshold = -10, turnover_type = &quot;threshold&quot;, base_turnover_rate = 0.05, n_new_applicants = 50, applicant_attraction_threshold = -0.5, max_application_time = 12, diversity_metric = &quot;blau&quot; # &quot;blau&quot; or &quot;shannon&quot; ) Value List containing: - final_organization: End state - metrics: Time series data.table - parameters: Used parameters - organization_snapshots: Periodic saves Examples # Basic simulation results &lt;- run_asa_simulation() # Custom parameters results &lt;- run_asa_simulation( n_steps = 520, initial_size = 200, params = list( growth_rate = 0.02, turnover_type = &quot;probabilistic&quot; ) ) 6.1.6.2 calculate_step_metrics() Compute metrics for single time step. Usage calculate_step_metrics(org, time_step) Arguments - org: Organization data.table - time_step: Current time Value data.table row with comprehensive metrics 6.1.6.3 save_simulation_results() Save simulation outputs to files. Usage save_simulation_results(results, filename = &quot;simulation_results&quot;, save_snapshots = FALSE) Arguments - results: Simulation results list - filename: Base filename - save_snapshots: Whether to save snapshots Details Creates files: - {filename}_metrics.csv - {filename}_params.rds - {filename}_final_org.csv - {filename}_snapshots.rds (optional) 6.2 Error Handling All functions validate inputs using checkmate: # Example validation assert_count(n_agents, positive = TRUE) assert_character(identity_categories, min.len = 1) assert_data_table(org) 6.3 Performance Notes Use vectorized functions for large organizations Snapshots are memory-intensive; save selectively Set verbose = FALSE for batch simulations Use data.table syntax for custom analyses "],["examples.html", "Chapter 7 Examples and Case Studies 7.1 Basic Examples 7.2 Advanced Examples 7.3 Case Studies 7.4 Best Practices from Examples 7.5 Code Snippets for Common Tasks", " Chapter 7 Examples and Case Studies This chapter provides practical examples and case studies demonstrating various uses of the ASA ABM v2. 7.1 Basic Examples 7.1.1 Example 1: Standard Simulation A basic simulation with default parameters: # Load the simulation engine source(&quot;simulation/engine.R&quot;) # Run a one-year simulation results &lt;- run_asa_simulation( n_steps = 52, # Weekly steps initial_size = 100, # Starting size verbose = TRUE ) # View final metrics final_metrics &lt;- tail(results$metrics, 1) print(final_metrics) # Plot organization size over time library(ggplot2) ggplot(results$metrics, aes(x = time, y = size)) + geom_line(color = &quot;darkblue&quot;, size = 1) + labs(title = &quot;Organization Size Over Time&quot;, x = &quot;Week&quot;, y = &quot;Number of Employees&quot;) + theme_minimal() 7.1.2 Example 2: High-Turnover Environment Simulating an organization with challenging conditions: # Configure high-turnover parameters high_turnover_params &lt;- list( turnover_threshold = -3, # Low satisfaction tolerance growth_rate = 0.05, # Aggressive hiring n_interactions_per_step = 2, # Limited interactions interaction_window = 5 # Short memory ) # Run simulation volatile_results &lt;- run_asa_simulation( n_steps = 260, initial_size = 50, params = high_turnover_params ) # Analyze turnover patterns library(dplyr) turnover_analysis &lt;- volatile_results$metrics %&gt;% mutate( period = ceiling(time / 13), # Quarterly size_change = size - lag(size, default = 50) ) %&gt;% group_by(period) %&gt;% summarise( avg_size = mean(size), total_turnover = sum(size_change[size_change &lt; 0]), turnover_rate = abs(total_turnover) / avg_size ) print(turnover_analysis) 7.1.3 Example 3: Diversity-Focused Hiring Testing different selection strategies: # Compare selection strategies strategies &lt;- c(&quot;conscientiousness&quot;, &quot;fit&quot;, &quot;random&quot;) strategy_results &lt;- list() for (strategy in strategies) { set.seed(123) # For comparability results &lt;- run_asa_simulation( n_steps = 156, # 3 years initial_size = 100, params = list( selection_criteria = strategy, growth_rate = 0.02 ), verbose = FALSE ) strategy_results[[strategy]] &lt;- results$metrics %&gt;% mutate(strategy = strategy) } # Combine and plot library(tidyr) combined_results &lt;- bind_rows(strategy_results) ggplot(combined_results, aes(x = time, y = identity_diversity, color = strategy)) + geom_line(size = 1) + labs(title = &quot;Identity Diversity by Selection Strategy&quot;, x = &quot;Time&quot;, y = &quot;Shannon Diversity Index&quot;) + theme_minimal() + scale_color_brewer(palette = &quot;Set1&quot;) 7.2 Advanced Examples 7.2.1 Example 4: Parameter Sensitivity Analysis Testing how different parameters affect outcomes: # Define parameter grid param_grid &lt;- expand.grid( growth_rate = c(0.01, 0.02, 0.05), turnover_threshold = c(-10, -5, -2), n_interactions = c(5, 10, 20) ) # Run simulations sensitivity_results &lt;- list() for (i in 1:nrow(param_grid)) { params &lt;- list( growth_rate = param_grid$growth_rate[i], turnover_threshold = param_grid$turnover_threshold[i], n_interactions_per_step = param_grid$n_interactions[i] ) results &lt;- run_asa_simulation( n_steps = 104, # 2 years initial_size = 100, params = params, verbose = FALSE ) # Extract key metrics final_state &lt;- tail(results$metrics, 1) sensitivity_results[[i]] &lt;- data.frame( param_grid[i,], final_size = final_state$size, final_satisfaction = final_state$avg_satisfaction, final_diversity = final_state$identity_diversity ) } # Analyze results sensitivity_df &lt;- bind_rows(sensitivity_results) # Create heatmap library(reshape2) size_matrix &lt;- dcast(sensitivity_df, growth_rate ~ turnover_threshold, value.var = &quot;final_size&quot;, fun.aggregate = mean) # Plot heatmap ggplot(melt(size_matrix), aes(x = factor(turnover_threshold), y = factor(growth_rate), fill = value)) + geom_tile() + geom_text(aes(label = round(value))) + scale_fill_gradient2(low = &quot;red&quot;, mid = &quot;white&quot;, high = &quot;green&quot;, midpoint = 100) + labs(title = &quot;Final Organization Size by Parameters&quot;, x = &quot;Turnover Threshold&quot;, y = &quot;Growth Rate&quot;) + theme_minimal() 7.2.2 Example 5: Intervention Analysis Testing organizational interventions: # Baseline simulation baseline &lt;- run_asa_simulation( n_steps = 104, initial_size = 100, params = list(tag = &quot;baseline&quot;), verbose = FALSE ) # Intervention: Improve interaction quality intervention &lt;- run_asa_simulation( n_steps = 104, initial_size = 100, params = list( n_interactions_per_step = 15, # Triple interactions interaction_window = 20, # Longer memory tag = &quot;intervention&quot; ), verbose = FALSE ) # Compare results comparison &lt;- bind_rows( baseline$metrics %&gt;% mutate(scenario = &quot;Baseline&quot;), intervention$metrics %&gt;% mutate(scenario = &quot;Intervention&quot;) ) # Plot satisfaction trajectories ggplot(comparison, aes(x = time, y = avg_satisfaction, color = scenario)) + geom_line(size = 1.2) + labs(title = &quot;Impact of Increased Interactions on Satisfaction&quot;, x = &quot;Time&quot;, y = &quot;Average Satisfaction&quot;) + theme_minimal() + scale_color_manual(values = c(&quot;Baseline&quot; = &quot;gray50&quot;, &quot;Intervention&quot; = &quot;darkgreen&quot;)) 7.3 Case Studies 7.3.1 Case Study 1: Startup Growth Dynamics Modeling a rapidly growing startup: # Startup parameters startup_params &lt;- list( # Aggressive growth growth_rate = 0.10, hiring_frequency = 2, n_new_applicants = 200, # Culture-focused selection selection_criteria = &quot;fit&quot;, # High interaction environment n_interactions_per_step = 20, interaction_window = 20, # Moderate turnover tolerance turnover_threshold = -5 ) # Run 2-year simulation startup_sim &lt;- run_asa_simulation( n_steps = 104, initial_size = 10, # Small founding team params = startup_params ) # Analyze growth phases growth_analysis &lt;- startup_sim$metrics %&gt;% mutate( phase = case_when( time &lt;= 26 ~ &quot;Founding&quot;, time &lt;= 52 ~ &quot;Early Growth&quot;, time &lt;= 78 ~ &quot;Scaling&quot;, TRUE ~ &quot;Maturing&quot; ) ) %&gt;% group_by(phase) %&gt;% summarise( start_size = first(size), end_size = last(size), growth_rate = (end_size - start_size) / start_size, avg_satisfaction = mean(avg_satisfaction), avg_diversity = mean(identity_diversity) ) print(growth_analysis) # Visualize growth trajectory ggplot(startup_sim$metrics, aes(x = time)) + geom_line(aes(y = size), color = &quot;blue&quot;, size = 1) + geom_line(aes(y = avg_satisfaction * 100), color = &quot;green&quot;, size = 1, linetype = &quot;dashed&quot;) + scale_y_continuous( name = &quot;Organization Size&quot;, sec.axis = sec_axis(~./100, name = &quot;Avg Satisfaction&quot;) ) + labs(title = &quot;Startup Growth and Satisfaction&quot;, x = &quot;Week&quot;) + theme_minimal() 7.3.2 Case Study 2: Merger Integration Simulating the integration of two organizational cultures: # Create two distinct organizations org_a &lt;- create_organization( n_agents = 80, identity_categories = c(&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;) # A-dominant ) org_b &lt;- create_organization( n_agents = 60, identity_categories = c(&quot;C&quot;, &quot;C&quot;, &quot;D&quot;, &quot;D&quot;, &quot;E&quot;) # Different culture ) # Merge organizations merged_org &lt;- rbind(org_a, org_b) merged_org$agent_id &lt;- paste0(&quot;merged_&quot;, seq_len(nrow(merged_org))) # Run post-merger simulation merger_params &lt;- list( growth_rate = 0, # No hiring during integration n_interactions_per_step = 15, # Encourage mixing turnover_threshold = -8 # Some tolerance for dissatisfaction ) # Initialize properly source(&quot;simulation/engine.R&quot;) merger_sim &lt;- list( final_organization = merged_org, metrics = data.table(), parameters = merger_params ) # Track cultural integration integration_metrics &lt;- data.frame() for (month in 1:12) { # Run one month month_results &lt;- run_asa_simulation( n_steps = 4, initial_size = nrow(merged_org), params = merger_params, verbose = FALSE ) # Calculate integration index interactions &lt;- initialize_interactions(month_results$final_organization) # Store metrics integration_metrics &lt;- rbind( integration_metrics, data.frame( month = month, size = get_organization_size(month_results$final_organization), diversity = calculate_identity_diversity(month_results$final_organization), satisfaction = calculate_average_satisfaction(month_results$final_organization) ) ) # Update for next iteration merged_org &lt;- month_results$final_organization } # Plot integration progress ggplot(integration_metrics, aes(x = month)) + geom_line(aes(y = satisfaction), color = &quot;blue&quot;, size = 1) + geom_line(aes(y = diversity), color = &quot;green&quot;, size = 1) + geom_point(aes(y = satisfaction), color = &quot;blue&quot;) + geom_point(aes(y = diversity), color = &quot;green&quot;) + labs(title = &quot;Post-Merger Integration Metrics&quot;, x = &quot;Months Post-Merger&quot;, y = &quot;Metric Value&quot;) + theme_minimal() 7.3.3 Case Study 3: Remote Work Transition Modeling the impact of remote work on organizational dynamics: # Pre-remote baseline pre_remote &lt;- run_asa_simulation( n_steps = 52, initial_size = 200, params = list( n_interactions_per_step = 10, interaction_window = 10 ), verbose = FALSE ) # Remote work scenario (reduced interactions) remote_params &lt;- list( n_interactions_per_step = 3, # Fewer spontaneous interactions interaction_window = 15, # But longer-lasting connections turnover_threshold = -7, # Slightly more tolerance growth_rate = 0.005 # Slower growth ) remote_sim &lt;- run_asa_simulation( n_steps = 52, initial_size = 200, params = remote_params, verbose = FALSE ) # Hybrid scenario hybrid_params &lt;- list( n_interactions_per_step = 6, # Moderate interactions interaction_window = 12, turnover_threshold = -8, growth_rate = 0.015 ) hybrid_sim &lt;- run_asa_simulation( n_steps = 52, initial_size = 200, params = hybrid_params, verbose = FALSE ) # Compare scenarios scenarios &lt;- bind_rows( pre_remote$metrics %&gt;% mutate(scenario = &quot;Office&quot;), remote_sim$metrics %&gt;% mutate(scenario = &quot;Remote&quot;), hybrid_sim$metrics %&gt;% mutate(scenario = &quot;Hybrid&quot;) ) # Multi-panel comparison library(gridExtra) p1 &lt;- ggplot(scenarios, aes(x = time, y = avg_satisfaction, color = scenario)) + geom_line(size = 1) + labs(title = &quot;Satisfaction&quot;, y = &quot;Average&quot;) + theme_minimal() + theme(legend.position = &quot;bottom&quot;) p2 &lt;- ggplot(scenarios, aes(x = time, y = identity_diversity, color = scenario)) + geom_line(size = 1) + labs(title = &quot;Diversity&quot;, y = &quot;Shannon Index&quot;) + theme_minimal() + theme(legend.position = &quot;bottom&quot;) p3 &lt;- ggplot(scenarios, aes(x = time, y = size, color = scenario)) + geom_line(size = 1) + labs(title = &quot;Organization Size&quot;, y = &quot;Employees&quot;) + theme_minimal() + theme(legend.position = &quot;bottom&quot;) grid.arrange(p1, p2, p3, ncol = 3) 7.4 Best Practices from Examples 7.4.1 1. Parameter Selection Start with default values and adjust gradually Consider realistic ranges for your context Document parameter choices and rationale 7.4.2 2. Analysis Approach Always visualize time series data Compare multiple scenarios Calculate summary statistics for key periods Consider both individual and aggregate metrics 7.4.3 3. Validation Run multiple replications with different seeds Check for sensitivity to initial conditions Validate against known organizational patterns Test extreme parameter values 7.4.4 4. Interpretation Remember agent-based models show possibilities, not predictions Focus on patterns and dynamics rather than exact values Consider emergent behaviors not explicitly programmed Use results to generate hypotheses for further testing 7.5 Code Snippets for Common Tasks 7.5.1 Batch Processing # Run multiple replications run_replications &lt;- function(n_reps, params) { results &lt;- list() for (i in 1:n_reps) { set.seed(i) results[[i]] &lt;- run_asa_simulation(params = params) } return(results) } 7.5.2 Custom Metrics # Add custom metric calculation calculate_custom_metric &lt;- function(org) { # Example: Personality homogeneity personality_vars &lt;- c(&quot;openness&quot;, &quot;conscientiousness&quot;, &quot;extraversion&quot;, &quot;agreeableness&quot;, &quot;emotional_stability&quot;) homogeneity &lt;- org[is_active == TRUE, lapply(.SD, function(x) 1/sd(x)), .SDcols = personality_vars] return(mean(as.numeric(homogeneity))) } 7.5.3 Visualization Helpers # Create standard plot theme theme_asa &lt;- function() { theme_minimal() + theme( plot.title = element_text(face = &quot;bold&quot;), legend.position = &quot;bottom&quot;, panel.grid.minor = element_blank() ) } # Time series with confidence bands plot_with_ci &lt;- function(results_list, metric) { # Calculate mean and CI across replications combined &lt;- bind_rows(lapply(seq_along(results_list), function(i) { results_list[[i]]$metrics %&gt;% mutate(rep = i) })) summary_stats &lt;- combined %&gt;% group_by(time) %&gt;% summarise( mean_val = mean(get(metric)), lower_ci = quantile(get(metric), 0.025), upper_ci = quantile(get(metric), 0.975) ) ggplot(summary_stats, aes(x = time)) + geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), alpha = 0.3) + geom_line(aes(y = mean_val), size = 1) + labs(y = metric) + theme_asa() } "],["recipes.html", "Chapter 8 Model Recipe Book 8.1 Introduction: The Cookbook Approach 8.2 Recipe 1: Creating a Homogeneous Organization 8.3 Recipe 2: The Diversity Paradox 8.4 Recipe 3: Rapid Growth Startup Dynamics 8.5 Recipe 4: Parameter Sensitivity Analysis 8.6 Recipe 5: Long-term Organizational Evolution 8.7 Best Practices from Recipes 8.8 Code Snippets for Common Tasks 8.9 Conclusion", " Chapter 8 Model Recipe Book 8.1 Introduction: The Cookbook Approach This chapter provides ready-to-use “recipes” for common organizational research scenarios using the ASA ABM v2. Each recipe addresses a specific research question, providing complete parameter configurations, runnable code, and interpretation guidance. Think of these recipes as starting points for your own research. You can: Use them directly to replicate common scenarios Modify parameters to explore variations Combine elements from multiple recipes Extract visualization and analysis techniques Each recipe follows a consistent structure: Research Question: What organizational phenomenon are we investigating? Key Parameters: Which model parameters drive this scenario? Implementation: Complete, runnable R code Expected Outcomes: What patterns should emerge? Visualization: How to effectively display results Insights: What can we learn about real organizations? # Source simulation engine source(&quot;../simulation/engine.R&quot;) # Common visualization theme theme_asa &lt;- function() { theme_minimal() + theme( plot.title = element_text(size = 14, face = &quot;bold&quot;), plot.subtitle = element_text(size = 12), legend.position = &quot;bottom&quot;, panel.grid.minor = element_blank() ) } # Helper function for parameter tables show_params &lt;- function(params, highlight = NULL) { param_df &lt;- data.frame( Parameter = names(params), Value = as.character(unlist(params)), stringsAsFactors = FALSE ) if (!is.null(highlight)) { param_df$Key &lt;- ifelse(param_df$Parameter %in% highlight, &quot;★&quot;, &quot;&quot;) } print(param_df) } 8.2 Recipe 1: Creating a Homogeneous Organization Research Question: How do strong selection criteria and social influence create organizational monocultures? Scenario: An organization with strong cultural fit requirements gradually becomes increasingly homogeneous, potentially limiting innovation and adaptability. 8.2.1 Key Parameters homogeneous_params &lt;- list( # Strong selection for conscientiousness selection_criteria = &quot;conscientiousness&quot;, # High homophily preferences homophily_preference = list(mean = 0.8, sd = 0.1), diversity_preference = list(mean = 0.2, sd = 0.1), # Frequent interactions reinforce similarity n_interactions_per_step = 10, interaction_window = 20, # Low turnover threshold keeps similar people turnover_threshold = -15, # Standard growth growth_rate = 0.01, hiring_frequency = 12 ) show_params(homogeneous_params, highlight = c(&quot;selection_criteria&quot;, &quot;homophily_preference&quot;, &quot;n_interactions_per_step&quot;)) 8.2.2 Implementation # Run the homogeneous organization simulation set.seed(42) homo_results &lt;- run_asa_simulation( n_steps = 260, initial_size = 100, params = homogeneous_params, verbose = FALSE ) # Extract metrics homo_metrics &lt;- homo_results$metrics # Calculate convergence point (when diversity drops below threshold) diversity_threshold &lt;- 0.5 convergence_step &lt;- homo_metrics[blau_index &lt; diversity_threshold, min(time_step)] cat(&quot;Diversity dropped below&quot;, diversity_threshold, &quot;at step:&quot;, convergence_step, &quot;\\n&quot;) 8.2.3 Visualization # Create multi-panel visualization library(gridExtra) # Panel 1: Diversity decline p1 &lt;- ggplot(homo_metrics, aes(x = time_step)) + geom_line(aes(y = blau_index), color = &quot;darkred&quot;, size = 1.2) + geom_hline(yintercept = diversity_threshold, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + geom_vline(xintercept = convergence_step, linetype = &quot;dotted&quot;) + annotate(&quot;text&quot;, x = convergence_step + 10, y = 0.6, label = &quot;Convergence&quot;, angle = 90, vjust = 0) + labs(title = &quot;Identity Diversity Decline&quot;, y = &quot;Blau&#39;s Index&quot;, x = &quot;Time Step&quot;) + theme_asa() # Panel 2: Personality convergence p2 &lt;- ggplot(homo_metrics, aes(x = time_step)) + geom_line(aes(y = sd_conscientiousness), color = &quot;darkblue&quot;, size = 1.2) + geom_line(aes(y = sd_openness), color = &quot;darkgreen&quot;, size = 1.2, linetype = &quot;dashed&quot;) + labs(title = &quot;Personality Homogenization&quot;, y = &quot;Standard Deviation&quot;, x = &quot;Time Step&quot;) + annotate(&quot;text&quot;, x = 200, y = homo_metrics[time_step == 200, sd_conscientiousness] + 0.02, label = &quot;Conscientiousness&quot;, color = &quot;darkblue&quot;) + annotate(&quot;text&quot;, x = 200, y = homo_metrics[time_step == 200, sd_openness] + 0.02, label = &quot;Openness&quot;, color = &quot;darkgreen&quot;) + theme_asa() # Panel 3: Satisfaction trajectory p3 &lt;- ggplot(homo_metrics, aes(x = time_step)) + geom_line(aes(y = avg_satisfaction), color = &quot;darkgreen&quot;, size = 1.2) + geom_ribbon(aes(ymin = avg_satisfaction - sd_satisfaction, ymax = avg_satisfaction + sd_satisfaction), alpha = 0.2, fill = &quot;green&quot;) + labs(title = &quot;Agent Satisfaction&quot;, y = &quot;Average Satisfaction&quot;, x = &quot;Time Step&quot;) + theme_asa() # Panel 4: Organization size p4 &lt;- ggplot(homo_metrics, aes(x = time_step)) + geom_line(aes(y = organization_size), color = &quot;purple&quot;, size = 1.2) + labs(title = &quot;Organization Growth&quot;, y = &quot;Number of Employees&quot;, x = &quot;Time Step&quot;) + theme_asa() # Combine plots grid.arrange(p1, p2, p3, p4, ncol = 2, top = &quot;Recipe 1: Evolution of a Homogeneous Organization&quot;) 8.2.4 Expected Outcomes and Insights Rapid Diversity Loss: Blau’s Index drops below 0.5 within 50-100 steps Personality Convergence: Standard deviation of selected trait (conscientiousness) approaches zero High Satisfaction: Homophily leads to high average satisfaction (&gt;5) Stable Growth: Low turnover enables steady organizational growth Organizational Insight: While homogeneous cultures can be efficient and harmonious, they risk groupthink and reduced innovation capacity. The high satisfaction masks potential vulnerabilities to environmental changes. 8.3 Recipe 2: The Diversity Paradox Research Question: Why do diversity initiatives sometimes fail despite good intentions? Scenario: An organization attempts to increase diversity through hiring but struggles with retention due to unchanged cultural dynamics. 8.3.1 Key Parameters diversity_paradox_params &lt;- list( # No selection on personality traits selection_criteria = &quot;random&quot;, # But strong internal homophily homophily_preference = list(mean = 0.9, sd = 0.05), diversity_preference = list(mean = 0.1, sd = 0.05), # Lower satisfaction threshold triggers more turnover turnover_threshold = -5, # Aggressive growth to bring in diversity growth_rate = 0.05, hiring_frequency = 4, # High interaction frequency amplifies cultural pressure n_interactions_per_step = 15, interaction_window = 10 ) show_params(diversity_paradox_params, highlight = c(&quot;selection_criteria&quot;, &quot;homophily_preference&quot;, &quot;turnover_threshold&quot;)) 8.3.2 Implementation set.seed(123) paradox_results &lt;- run_asa_simulation( n_steps = 260, initial_size = 100, params = diversity_paradox_params, verbose = FALSE ) # Analyze hiring vs retention paradox_org &lt;- paradox_results$final_organization paradox_metrics &lt;- paradox_results$metrics # Calculate hire diversity vs organization diversity hire_diversity &lt;- numeric(nrow(paradox_metrics)) for(i in 1:nrow(paradox_metrics)) { new_hires &lt;- paradox_org[hire_date == i &amp; is_active == TRUE] if(nrow(new_hires) &gt; 0) { hire_diversity[i] &lt;- calculate_blau_index(new_hires$identity_category) } } paradox_metrics$hire_diversity &lt;- hire_diversity 8.3.3 Visualization # Panel 1: Hiring diversity vs organizational diversity p1 &lt;- ggplot(paradox_metrics[hire_diversity &gt; 0], aes(x = time_step)) + geom_point(aes(y = hire_diversity), color = &quot;orange&quot;, alpha = 0.6) + geom_line(aes(y = blau_index), color = &quot;purple&quot;, size = 1.2) + labs(title = &quot;The Diversity Paradox&quot;, subtitle = &quot;High diverse hiring (orange points) doesn&#39;t translate to organizational diversity (purple line)&quot;, y = &quot;Diversity (Blau&#39;s Index)&quot;, x = &quot;Time Step&quot;) + theme_asa() # Panel 2: Turnover by identity category turnover_summary &lt;- paradox_org[is_active == FALSE, .N, by = identity_category] total_by_category &lt;- paradox_org[, .N, by = identity_category] turnover_summary &lt;- merge(turnover_summary, total_by_category, by = &quot;identity_category&quot;) turnover_summary[, turnover_rate := N.x / N.y] p2 &lt;- ggplot(turnover_summary, aes(x = identity_category, y = turnover_rate)) + geom_col(fill = &quot;darkred&quot;) + labs(title = &quot;Differential Turnover by Identity Category&quot;, y = &quot;Turnover Rate&quot;, x = &quot;Identity Category&quot;) + theme_asa() # Panel 3: Satisfaction distribution final_state &lt;- paradox_org[is_active == TRUE] p3 &lt;- ggplot(final_state, aes(x = satisfaction, fill = identity_category)) + geom_histogram(bins = 20, alpha = 0.7, position = &quot;identity&quot;) + facet_wrap(~ identity_category) + labs(title = &quot;Satisfaction Distribution by Identity Category&quot;, x = &quot;Satisfaction Score&quot;, y = &quot;Count&quot;) + theme_asa() + theme(legend.position = &quot;none&quot;) # Panel 4: Tenure analysis p4 &lt;- ggplot(final_state, aes(x = identity_category, y = tenure)) + geom_boxplot(aes(fill = identity_category)) + labs(title = &quot;Tenure Distribution by Identity Category&quot;, y = &quot;Tenure (weeks)&quot;, x = &quot;Identity Category&quot;) + theme_asa() + theme(legend.position = &quot;none&quot;) grid.arrange(p1, p2, p3, p4, ncol = 2, top = &quot;Recipe 2: The Diversity Paradox - Hiring Without Inclusion&quot;) 8.3.4 Expected Outcomes and Insights Hiring-Retention Gap: 60-80% diversity in new hires, but organizational diversity remains low Differential Turnover: Minority categories show 2-3x higher turnover rates Satisfaction Inequality: Clear satisfaction gaps between dominant and minority groups Short Tenure: Diverse hires leave quickly, often within 20-30 time steps Organizational Insight: Diversity initiatives focused solely on hiring without addressing cultural dynamics and inclusion often fail. Success requires systemic change in how organizations value and integrate different perspectives. 8.4 Recipe 3: Rapid Growth Startup Dynamics Research Question: How does rapid scaling affect organizational culture and cohesion? Scenario: A startup experiencing hockey-stick growth must balance maintaining culture with rapid hiring. 8.4.1 Key Parameters startup_params &lt;- list( # Aggressive growth phases growth_rate = 0.10, # 10% per hiring cycle hiring_frequency = 2, # Hire every 2 weeks # Initially strong culture selection_criteria = &quot;fit&quot;, # But weakening influence as size grows n_interactions_per_step = 5, # Can&#39;t maintain connections interaction_window = 5, # Shorter organizational memory # Higher turnover during growth turnover_threshold = -7, # Start with strong homophily homophily_preference = list(mean = 0.7, sd = 0.1), diversity_preference = list(mean = 0.3, sd = 0.1) ) show_params(startup_params, highlight = c(&quot;growth_rate&quot;, &quot;hiring_frequency&quot;, &quot;interaction_window&quot;)) 8.4.2 Implementation set.seed(456) startup_results &lt;- run_asa_simulation( n_steps = 156, # 3 years initial_size = 20, # Small founding team params = startup_params, verbose = FALSE ) # Analyze growth phases startup_metrics &lt;- startup_results$metrics startup_metrics[, growth_phase := cut( time_step, breaks = c(0, 26, 78, 130, 156), labels = c(&quot;Founding&quot;, &quot;Early Growth&quot;, &quot;Scaling&quot;, &quot;Maturity&quot;), include.lowest = TRUE )] # Calculate phase-specific metrics phase_summary &lt;- startup_metrics[, .( avg_size = mean(organization_size), growth_rate = (last(organization_size) - first(organization_size)) / first(organization_size), avg_diversity = mean(blau_index), avg_satisfaction = mean(avg_satisfaction), culture_drift = last(avg_conscientiousness) - first(avg_conscientiousness) ), by = growth_phase] print(phase_summary) 8.4.3 Visualization # Panel 1: Growth trajectory with phases p1 &lt;- ggplot(startup_metrics, aes(x = time_step, y = organization_size)) + geom_line(size = 1.5, color = &quot;darkgreen&quot;) + geom_rect(data = data.frame( xmin = c(0, 26, 78, 130), xmax = c(26, 78, 130, 156), phase = c(&quot;Founding&quot;, &quot;Early Growth&quot;, &quot;Scaling&quot;, &quot;Maturity&quot;) ), aes(xmin = xmin, xmax = xmax, ymin = 0, ymax = Inf, fill = phase), alpha = 0.2, inherit.aes = FALSE) + scale_fill_manual(values = c(&quot;Founding&quot; = &quot;blue&quot;, &quot;Early Growth&quot; = &quot;green&quot;, &quot;Scaling&quot; = &quot;orange&quot;, &quot;Maturity&quot; = &quot;purple&quot;)) + labs(title = &quot;Startup Growth Trajectory&quot;, y = &quot;Organization Size&quot;, x = &quot;Time Step&quot;, fill = &quot;Growth Phase&quot;) + theme_asa() # Panel 2: Cultural metrics evolution p2 &lt;- ggplot(startup_metrics, aes(x = time_step)) + geom_line(aes(y = blau_index, color = &quot;Identity Diversity&quot;), size = 1.2) + geom_line(aes(y = avg_satisfaction / 10, color = &quot;Avg Satisfaction (scaled)&quot;), size = 1.2) + geom_line(aes(y = sd_conscientiousness * 5, color = &quot;Personality Variance (scaled)&quot;), size = 1.2) + scale_color_manual(values = c(&quot;Identity Diversity&quot; = &quot;purple&quot;, &quot;Avg Satisfaction (scaled)&quot; = &quot;green&quot;, &quot;Personality Variance (scaled)&quot; = &quot;orange&quot;)) + labs(title = &quot;Cultural Evolution During Growth&quot;, y = &quot;Metric Value&quot;, x = &quot;Time Step&quot;, color = &quot;Metric&quot;) + theme_asa() # Panel 3: New hire integration startup_org &lt;- startup_results$final_organization recent_hires &lt;- startup_org[hire_date &gt; 100 &amp; is_active == TRUE] veteran_employees &lt;- startup_org[hire_date &lt; 50 &amp; is_active == TRUE] integration_data &lt;- rbind( data.frame(group = &quot;Veterans&quot;, satisfaction = veteran_employees$satisfaction, conscientiousness = veteran_employees$conscientiousness), data.frame(group = &quot;Recent Hires&quot;, satisfaction = recent_hires$satisfaction, conscientiousness = recent_hires$conscientiousness) ) p3 &lt;- ggplot(integration_data, aes(x = conscientiousness, y = satisfaction, color = group)) + geom_point(alpha = 0.6, size = 3) + stat_ellipse(level = 0.95) + scale_color_manual(values = c(&quot;Veterans&quot; = &quot;darkblue&quot;, &quot;Recent Hires&quot; = &quot;darkorange&quot;)) + labs(title = &quot;Cultural Gap: Veterans vs Recent Hires&quot;, x = &quot;Conscientiousness&quot;, y = &quot;Satisfaction&quot;, color = &quot;Employee Group&quot;) + theme_asa() # Panel 4: Phase transition analysis transition_points &lt;- startup_metrics[, .( size_change = diff(organization_size), diversity_change = diff(blau_index), satisfaction_change = diff(avg_satisfaction) ), by = growth_phase] p4 &lt;- transition_points %&gt;% pivot_longer(cols = ends_with(&quot;_change&quot;), names_to = &quot;metric&quot;, values_to = &quot;change&quot;) %&gt;% ggplot(aes(x = growth_phase, y = change, fill = metric)) + geom_boxplot(alpha = 0.7) + scale_fill_brewer(palette = &quot;Set2&quot;, labels = c(&quot;Diversity Change&quot;, &quot;Satisfaction Change&quot;, &quot;Size Change&quot;)) + labs(title = &quot;Volatility by Growth Phase&quot;, x = &quot;Growth Phase&quot;, y = &quot;Step-to-Step Change&quot;, fill = &quot;Metric&quot;) + theme_asa() grid.arrange(p1, p2, p3, p4, ncol = 2, top = &quot;Recipe 3: Rapid Growth Startup Dynamics&quot;) 8.4.4 Expected Outcomes and Insights Exponential Growth: 10x size increase possible in 3 years Cultural Dilution: Diversity increases 50-70% during scaling Integration Challenges: Clear clusters between veterans and new hires Volatility Increases: Higher variance in all metrics during scaling phase Organizational Insight: Rapid scaling creates inevitable cultural dilution. Successful startups must intentionally reinforce culture through onboarding, rituals, and veteran employee engagement. 8.5 Recipe 4: Parameter Sensitivity Analysis Research Question: Which parameters most strongly influence organizational outcomes? Scenario: Systematic exploration of parameter space to understand model dynamics. 8.5.1 Key Parameters # Define parameter grid for sensitivity analysis param_grid &lt;- expand.grid( growth_rate = c(0.00, 0.01, 0.05), turnover_threshold = c(-15, -10, -5), n_interactions = c(5, 10, 20), homophily_strength = c(0.3, 0.6, 0.9) ) # Show sample of parameter combinations cat(&quot;Testing&quot;, nrow(param_grid), &quot;parameter combinations\\n&quot;) print(head(param_grid, 10)) 8.5.2 Implementation # Run sensitivity analysis (subset for demonstration) set.seed(789) sensitivity_results &lt;- list() # Run subset of simulations sample_indices &lt;- sample(1:nrow(param_grid), 12) # Run 12 for demo for (i in sample_indices) { params &lt;- list( growth_rate = param_grid$growth_rate[i], turnover_threshold = param_grid$turnover_threshold[i], n_interactions_per_step = param_grid$n_interactions[i], homophily_preference = list(mean = param_grid$homophily_strength[i], sd = 0.1) ) result &lt;- run_asa_simulation( n_steps = 104, # 2 years initial_size = 100, params = params, verbose = FALSE ) # Extract summary metrics final_metrics &lt;- tail(result$metrics, 1) sensitivity_results[[i]] &lt;- data.frame( param_grid[i,], final_size = final_metrics$organization_size, final_diversity = final_metrics$blau_index, final_satisfaction = final_metrics$avg_satisfaction, total_turnover = sum(result$final_organization$is_active == FALSE) ) } # Combine results sensitivity_df &lt;- bind_rows(sensitivity_results) 8.5.3 Visualization # Panel 1: Growth rate impact p1 &lt;- ggplot(sensitivity_df, aes(x = factor(growth_rate), y = final_size)) + geom_boxplot(aes(fill = factor(turnover_threshold))) + scale_fill_brewer(palette = &quot;RdYlBu&quot;, name = &quot;Turnover\\nThreshold&quot;) + labs(title = &quot;Organization Size: Growth vs Turnover&quot;, x = &quot;Growth Rate&quot;, y = &quot;Final Organization Size&quot;) + theme_asa() # Panel 2: Diversity outcomes p2 &lt;- ggplot(sensitivity_df, aes(x = homophily_strength, y = final_diversity)) + geom_point(aes(color = factor(n_interactions), size = final_size), alpha = 0.7) + geom_smooth(method = &quot;lm&quot;, se = TRUE, color = &quot;black&quot;, linetype = &quot;dashed&quot;) + scale_color_brewer(palette = &quot;Set1&quot;, name = &quot;Interactions\\nper Step&quot;) + scale_size_continuous(name = &quot;Final Size&quot;) + labs(title = &quot;Diversity: Homophily vs Interactions&quot;, x = &quot;Homophily Strength&quot;, y = &quot;Final Diversity (Blau&#39;s Index)&quot;) + theme_asa() # Panel 3: Parameter importance (mock random forest importance) # In practice, would use actual RF or similar param_importance &lt;- data.frame( parameter = c(&quot;Homophily Strength&quot;, &quot;Turnover Threshold&quot;, &quot;Growth Rate&quot;, &quot;N Interactions&quot;), importance = c(0.35, 0.30, 0.20, 0.15) ) p3 &lt;- ggplot(param_importance, aes(x = reorder(parameter, importance), y = importance)) + geom_col(fill = &quot;darkblue&quot;) + coord_flip() + labs(title = &quot;Parameter Importance for Diversity Outcome&quot;, x = &quot;&quot;, y = &quot;Relative Importance&quot;) + theme_asa() # Panel 4: Interaction effects heatmap interaction_summary &lt;- sensitivity_df %&gt;% group_by(homophily_strength, turnover_threshold) %&gt;% summarise(avg_satisfaction = mean(final_satisfaction), .groups = &quot;drop&quot;) p4 &lt;- ggplot(interaction_summary, aes(x = factor(homophily_strength), y = factor(turnover_threshold), fill = avg_satisfaction)) + geom_tile() + scale_fill_gradient2(low = &quot;red&quot;, mid = &quot;white&quot;, high = &quot;green&quot;, midpoint = 0, name = &quot;Avg\\nSatisfaction&quot;) + labs(title = &quot;Satisfaction: Homophily × Turnover Interaction&quot;, x = &quot;Homophily Strength&quot;, y = &quot;Turnover Threshold&quot;) + theme_asa() grid.arrange(p1, p2, p3, p4, ncol = 2, top = &quot;Recipe 4: Parameter Sensitivity Analysis&quot;) 8.5.4 Expected Outcomes and Insights Growth-Turnover Balance: High growth can’t compensate for very high turnover Homophily Dominates Diversity: Strongest predictor of final diversity Interaction Effects: Parameters interact in non-linear ways Threshold Behaviors: Some parameters show sudden transitions Organizational Insight: Understanding parameter sensitivity helps identify key leverage points for organizational interventions. Focus on the parameters with highest impact for efficient change. 8.6 Recipe 5: Long-term Organizational Evolution Research Question: What are the long-term equilibrium states of organizations? Scenario: Tracking organizations over extended time periods to identify stable states and cycles. 8.6.1 Key Parameters longterm_params &lt;- list( # Moderate, sustainable parameters growth_rate = 0.005, # 0.5% growth turnover_threshold = -10, # Standard interaction patterns n_interactions_per_step = 10, interaction_window = 20, # Balanced preferences homophily_preference = list(mean = 0.5, sd = 0.2), diversity_preference = list(mean = 0.5, sd = 0.2), # Selection on fit selection_criteria = &quot;fit&quot; ) show_params(longterm_params) 8.6.2 Implementation set.seed(2024) longterm_results &lt;- run_asa_simulation( n_steps = 520, # 10 years initial_size = 100, params = longterm_params, verbose = FALSE ) # Identify equilibrium and cycles longterm_metrics &lt;- longterm_results$metrics # Calculate moving averages to identify trends window_size &lt;- 26 # 6 months longterm_metrics[, `:=`( ma_size = frollmean(organization_size, window_size, align = &quot;right&quot;), ma_diversity = frollmean(blau_index, window_size, align = &quot;right&quot;), ma_satisfaction = frollmean(avg_satisfaction, window_size, align = &quot;right&quot;) )] # Detect cycles using autocorrelation acf_diversity &lt;- acf(longterm_metrics$blau_index[!is.na(longterm_metrics$blau_index)], lag.max = 100, plot = FALSE) cycle_length &lt;- which(acf_diversity$acf[-1] == max(acf_diversity$acf[-1]))[1] cat(&quot;Detected cycle length:&quot;, cycle_length, &quot;steps\\n&quot;) 8.6.3 Visualization # Panel 1: Long-term trajectories p1 &lt;- ggplot(longterm_metrics[!is.na(ma_size)], aes(x = time_step)) + geom_line(aes(y = organization_size), alpha = 0.3, color = &quot;gray&quot;) + geom_line(aes(y = ma_size), color = &quot;darkblue&quot;, size = 1.2) + labs(title = &quot;Long-term Organization Size&quot;, subtitle = &quot;Gray: actual, Blue: 6-month moving average&quot;, y = &quot;Organization Size&quot;, x = &quot;Time Step&quot;) + theme_asa() # Panel 2: Diversity cycles p2 &lt;- ggplot(longterm_metrics[!is.na(ma_diversity)], aes(x = time_step)) + geom_line(aes(y = blau_index), alpha = 0.3, color = &quot;gray&quot;) + geom_line(aes(y = ma_diversity), color = &quot;purple&quot;, size = 1.2) + geom_hline(yintercept = mean(longterm_metrics$blau_index, na.rm = TRUE), linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs(title = &quot;Diversity Cycles&quot;, subtitle = &quot;Red line: long-term average&quot;, y = &quot;Blau&#39;s Index&quot;, x = &quot;Time Step&quot;) + theme_asa() # Panel 3: Phase space plot phase_data &lt;- longterm_metrics[seq(1, nrow(longterm_metrics), by = 4)] # Sample every month p3 &lt;- ggplot(phase_data, aes(x = blau_index, y = avg_satisfaction)) + geom_path(alpha = 0.5, color = &quot;darkgreen&quot;) + geom_point(aes(color = time_step), size = 2) + scale_color_gradient(low = &quot;blue&quot;, high = &quot;red&quot;, name = &quot;Time&quot;) + labs(title = &quot;Phase Space: Diversity vs Satisfaction&quot;, x = &quot;Diversity (Blau&#39;s Index)&quot;, y = &quot;Average Satisfaction&quot;) + theme_asa() # Panel 4: Equilibrium analysis # Calculate stability metrics over time windows stability_windows &lt;- longterm_metrics[, .( window = ceiling(time_step / 52), # Annual windows size_stability = 1 / (sd(organization_size) + 1), diversity_stability = 1 / (sd(blau_index) + 1), satisfaction_stability = 1 / (sd(avg_satisfaction) + 1) ), by = ceiling(time_step / 52)] stability_long &lt;- stability_windows %&gt;% pivot_longer(cols = ends_with(&quot;_stability&quot;), names_to = &quot;metric&quot;, values_to = &quot;stability&quot;) p4 &lt;- ggplot(stability_long, aes(x = ceiling, y = stability, fill = metric)) + geom_col(position = &quot;dodge&quot;) + scale_fill_brewer(palette = &quot;Set3&quot;, labels = c(&quot;Diversity&quot;, &quot;Satisfaction&quot;, &quot;Size&quot;)) + labs(title = &quot;System Stability Over Time&quot;, subtitle = &quot;Higher values indicate more stable periods&quot;, x = &quot;Year&quot;, y = &quot;Stability Index&quot;, fill = &quot;Metric&quot;) + theme_asa() grid.arrange(p1, p2, p3, p4, ncol = 2, top = &quot;Recipe 5: Long-term Organizational Evolution&quot;) 8.6.4 Expected Outcomes and Insights Equilibrium States: Organizations tend toward stable attractor states Diversity Cycles: Natural oscillations in diversity metrics Path Dependence: Early conditions influence long-term outcomes Stability Periods: Alternating periods of stability and change Organizational Insight: Organizations don’t reach static equilibria but rather dynamic steady states with natural cycles. Understanding these patterns helps anticipate and manage organizational change. 8.7 Best Practices from Recipes 8.7.1 1. Parameter Selection Start with default values and adjust gradually Consider realistic ranges for your context Document parameter choices and rationale Test sensitivity to key parameters 8.7.2 2. Analysis Approach Always visualize time series data Compare multiple scenarios Calculate summary statistics for key periods Look for both trends and cycles Consider phase transitions and threshold effects 8.7.3 3. Validation Run multiple replications with different seeds Check for sensitivity to initial conditions Validate against known organizational patterns Test extreme parameter values Compare with empirical data when available 8.7.4 4. Interpretation Agent-based models show possibilities, not predictions Focus on patterns and dynamics rather than exact values Consider emergent behaviors not explicitly programmed Use results to generate hypotheses for further testing Think about real-world interventions suggested by results 8.8 Code Snippets for Common Tasks 8.8.1 Running Multiple Replications run_replications &lt;- function(n_reps, base_params, n_steps = 260) { results &lt;- list() for (i in 1:n_reps) { set.seed(i * 1000) # Reproducible seeds results[[i]] &lt;- run_asa_simulation( n_steps = n_steps, initial_size = 100, params = base_params, verbose = FALSE ) } return(results) } # Aggregate results across replications aggregate_replications &lt;- function(rep_results) { metrics_list &lt;- lapply(rep_results, function(x) { x$metrics[, rep := which(sapply(rep_results, identical, x))] }) combined_metrics &lt;- rbindlist(metrics_list) summary_metrics &lt;- combined_metrics[, .( avg_size = mean(organization_size), sd_size = sd(organization_size), avg_diversity = mean(blau_index), sd_diversity = sd(blau_index), avg_satisfaction = mean(avg_satisfaction), sd_satisfaction = sd(avg_satisfaction) ), by = time_step] return(summary_metrics) } 8.8.2 Custom Visualization Functions # Plot with confidence intervals plot_with_ci &lt;- function(summary_metrics, metric_name, color = &quot;darkblue&quot;) { avg_col &lt;- paste0(&quot;avg_&quot;, metric_name) sd_col &lt;- paste0(&quot;sd_&quot;, metric_name) ggplot(summary_metrics, aes_string(x = &quot;time_step&quot;)) + geom_ribbon(aes_string(ymin = paste0(avg_col, &quot; - &quot;, sd_col), ymax = paste0(avg_col, &quot; + &quot;, sd_col)), alpha = 0.3, fill = color) + geom_line(aes_string(y = avg_col), color = color, size = 1.2) + labs(title = paste(&quot;Average&quot;, metric_name, &quot;with Standard Deviation&quot;), y = metric_name, x = &quot;Time Step&quot;) + theme_asa() } # Create dashboard of key metrics create_dashboard &lt;- function(metrics_data, title = &quot;Simulation Dashboard&quot;) { p1 &lt;- ggplot(metrics_data, aes(x = time_step, y = organization_size)) + geom_line(color = &quot;darkgreen&quot;) + labs(title = &quot;Organization Size&quot;, y = &quot;Size&quot;) + theme_asa() p2 &lt;- ggplot(metrics_data, aes(x = time_step, y = blau_index)) + geom_line(color = &quot;purple&quot;) + labs(title = &quot;Diversity&quot;, y = &quot;Blau&#39;s Index&quot;) + theme_asa() p3 &lt;- ggplot(metrics_data, aes(x = time_step, y = avg_satisfaction)) + geom_line(color = &quot;darkblue&quot;) + labs(title = &quot;Satisfaction&quot;, y = &quot;Average&quot;) + theme_asa() p4 &lt;- ggplot(metrics_data, aes(x = time_step, y = avg_conscientiousness)) + geom_line(color = &quot;darkorange&quot;) + labs(title = &quot;Conscientiousness&quot;, y = &quot;Average&quot;) + theme_asa() grid.arrange(p1, p2, p3, p4, ncol = 2, top = title) } 8.8.3 Advanced Analysis Functions # Detect organizational phases detect_phases &lt;- function(metrics_data, window = 26) { # Calculate rolling statistics metrics_data[, `:=`( growth_rate = c(NA, diff(organization_size)) / organization_size, diversity_change = c(NA, diff(blau_index)), satisfaction_change = c(NA, diff(avg_satisfaction)) )] # Identify phase transitions metrics_data[, phase := &quot;stable&quot;] metrics_data[abs(growth_rate) &gt; 0.05, phase := &quot;growth&quot;] metrics_data[growth_rate &lt; -0.02, phase := &quot;contraction&quot;] metrics_data[abs(diversity_change) &gt; 0.05, phase := &quot;transition&quot;] return(metrics_data) } # Calculate organizational health index calculate_health_index &lt;- function(metrics_data) { metrics_data[, health_index := (organization_size / max(organization_size)) * 0.25 + blau_index * 0.25 + (avg_satisfaction / 10) * 0.25 + (1 - sd_satisfaction / 5) * 0.25 ] return(metrics_data) } 8.9 Conclusion These recipes provide starting points for exploring organizational dynamics with the ASA ABM v2. By modifying parameters and combining elements from different recipes, researchers can investigate a wide range of organizational phenomena. Remember that the value of agent-based modeling lies not in precise prediction but in understanding the mechanisms that drive organizational behavior and identifying leverage points for intervention. "],["contributors-guide.html", "Chapter 9 Contributor’s Walkthrough 9.1 Getting Started as a Contributor 9.2 Step-by-Step Feature Tutorial: Adding a New Personality Trait 9.3 Code Flow Walkthrough 9.4 Testing Philosophy 9.5 Development Best Practices 9.6 Git Workflow 9.7 Common Development Tasks 9.8 Debugging Tips 9.9 Summary 9.10 Additional Resources", " Chapter 9 Contributor’s Walkthrough Welcome to the ASA ABM v2 contributor’s guide! This chapter provides a practical walkthrough for developers who want to contribute to or extend the codebase. Whether you’re adding new features, fixing bugs, or improving performance, this guide will help you navigate the codebase effectively. 9.1 Getting Started as a Contributor 9.1.1 Setting up the Development Environment Clone the repository: git clone [repository-url] cd asa_abm_v2 Install R dependencies: # Core dependencies install.packages(c( &quot;data.table&quot;, # High-performance data manipulation &quot;checkmate&quot;, # Input validation &quot;ggplot2&quot;, # Visualization &quot;plotly&quot;, # Interactive plots &quot;tidyverse&quot;, # Data manipulation utilities &quot;testthat&quot;, # Testing framework &quot;microbenchmark&quot;, # Performance testing &quot;profvis&quot; # Profiling tool )) # Documentation dependencies install.packages(c( &quot;bookdown&quot;, &quot;knitr&quot;, &quot;rmarkdown&quot; )) Verify installation: source(&quot;run_simulation.R&quot;) # Run a quick test simulation test_sim &lt;- run_asa_simulation( n_steps = 10, initial_size = 20, verbose = TRUE ) 9.1.2 Understanding the Codebase Structure The codebase follows a modular architecture: asa_abm_v2/ ├── core/ # Core components │ ├── agent.R # Agent definitions │ ├── organization.R # Organization structure │ └── interactions.R # Social interactions ├── simulation/ # Simulation logic │ ├── engine.R # Main simulation loop │ ├── hiring.R # Hiring processes │ └── turnover.R # Turnover mechanisms ├── analysis/ # Analysis tools ├── tests/ # Test suite ├── config/ # Configuration files └── docs/ # Documentation 9.1.3 Running Tests and Examples # Run all tests testthat::test_dir(&quot;tests/&quot;) # Run specific test file testthat::test_file(&quot;tests/test_agent.R&quot;) # Run example simulations source(&quot;docs/vignettes/basic_simulation.R&quot;) 9.2 Step-by-Step Feature Tutorial: Adding a New Personality Trait Let’s walk through adding a new personality trait called “risk_tolerance” to the simulation. This tutorial shows exactly which files need modification and how changes flow through the system. 9.2.1 Step 1: Update Agent Definition First, modify core/agent.R to include the new trait: # In create_applicant_pool() function around line 30 create_applicant_pool &lt;- function(n_applicants = 50, identity_categories = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;)) { # ... existing code ... # Create applicant pool applicants &lt;- data.table( agent_id = applicant_ids, identity_category = sample(identity_categories, n_applicants, replace = TRUE), # Big Five personality traits openness = rnorm(n_applicants, mean = 0, sd = 1), conscientiousness = rnorm(n_applicants, mean = 0, sd = 1), extraversion = rnorm(n_applicants, mean = 0, sd = 1), agreeableness = rnorm(n_applicants, mean = 0, sd = 1), emotional_stability = rnorm(n_applicants, mean = 0, sd = 1), # NEW TRAIT: Risk tolerance risk_tolerance = rnorm(n_applicants, mean = 0, sd = 1), # Preferences diversity_preference = rnorm(n_applicants, mean = 0, sd = 1), homophily_preference = rnorm(n_applicants, mean = 0, sd = 1), # Application state attraction = 0, application_time = 0 ) # ... rest of function ... } # Also update convert_to_employee() function convert_to_employee &lt;- function(applicant, hire_time) { employee &lt;- copy(applicant) employee[, `:=`( hire_time = hire_time, tenure = 0, satisfaction = 0, performance = calculate_initial_performance(applicant), risk_taking_behavior = 0 # NEW: Initialize behavior based on trait )] return(employee) } # NEW FUNCTION: Calculate risk-based performance modifier calculate_risk_performance_modifier &lt;- function(risk_tolerance) { # High risk tolerance can lead to bigger wins or losses risk_factor &lt;- pnorm(risk_tolerance) # Convert to 0-1 scale modifier &lt;- rnorm(1, mean = 0, sd = risk_factor * 0.2) return(modifier) } 9.2.2 Step 2: Update Organization Initialization Modify core/organization.R to handle the new trait: # In initialize_organization() function initialize_organization &lt;- function(size = 100, identity_categories = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;), params = list()) { # ... existing code ... # Create initial employees with new trait employees &lt;- data.table( agent_id = agent_ids, identity_category = sample(identity_categories, size, replace = TRUE), # Personality traits openness = rnorm(size, mean = 0, sd = 1), conscientiousness = rnorm(size, mean = 0, sd = 1), extraversion = rnorm(size, mean = 0, sd = 1), agreeableness = rnorm(size, mean = 0, sd = 1), emotional_stability = rnorm(size, mean = 0, sd = 1), risk_tolerance = rnorm(size, mean = 0, sd = 1), # NEW # ... rest of initialization ... ) # ... rest of function ... } 9.2.3 Step 3: Incorporate into Interactions Update core/interactions.R to use the new trait: # Add risk tolerance influence to satisfaction calculation calculate_interaction_satisfaction &lt;- function(agent1, agent2, org_culture = NULL) { # ... existing similarity calculations ... # NEW: Risk tolerance compatibility risk_compatibility &lt;- 1 - abs(agent1$risk_tolerance - agent2$risk_tolerance) / 4 # Update satisfaction calculation satisfaction &lt;- mean(c( identity_match, personality_similarity, risk_compatibility # NEW component )) # Apply cultural moderation if available if (!is.null(org_culture)) { culture_fit &lt;- calculate_culture_fit(agent1, org_culture) # NEW: Risk-taking culture modifier if (org_culture$risk_taking_culture &gt; 0) { risk_bonus &lt;- agent1$risk_tolerance * org_culture$risk_taking_culture * 0.1 satisfaction &lt;- satisfaction + risk_bonus } } return(satisfaction) } 9.2.4 Step 4: Update Selection Criteria Modify simulation/hiring.R to allow selection based on risk tolerance: # In evaluate_applicants() function evaluate_applicants &lt;- function(applicants, org_state, selection_criteria = &quot;conscientiousness&quot;) { # ... existing code ... # Evaluate based on criteria if (selection_criteria == &quot;conscientiousness&quot;) { applicants[, selection_score := conscientiousness] } else if (selection_criteria == &quot;cultural_fit&quot;) { applicants[, selection_score := calculate_cultural_fit(.SD, org_culture), by = agent_id] } else if (selection_criteria == &quot;risk_tolerance&quot;) { # NEW # Organizations might want risk-takers or risk-averse employees target_risk &lt;- org_state$params$target_risk_level %||% 0 applicants[, selection_score := -abs(risk_tolerance - target_risk)] } else if (selection_criteria == &quot;balanced&quot;) { # NEW: Include risk tolerance in balanced selection applicants[, selection_score := ( conscientiousness * 0.3 + emotional_stability * 0.2 + agreeableness * 0.2 + openness * 0.15 + extraversion * 0.1 + risk_tolerance * org_state$params$risk_weight %||% 0.05 )] } # ... rest of function ... } 9.2.5 Step 5: Add Performance Impact Update performance calculations in simulation/engine.R: # Add new function for risk-based events simulate_risk_events &lt;- function(employees, org_state) { # High risk tolerance employees may generate volatile outcomes risk_takers &lt;- employees[risk_tolerance &gt; 1] if (nrow(risk_takers) &gt; 0) { risk_takers[, risk_event := runif(.N) &lt; pnorm(risk_tolerance) * 0.1] # Calculate performance impact risk_takers[risk_event == TRUE, performance_modifier := calculate_risk_performance_modifier(risk_tolerance)] # Update organization metrics total_impact &lt;- sum(risk_takers$performance_modifier, na.rm = TRUE) org_state$metrics$risk_impact &lt;- c(org_state$metrics$risk_impact, total_impact) } return(employees) } # Integrate into main simulation loop run_simulation_step &lt;- function(org_state, step, params) { # ... existing step logic ... # NEW: Simulate risk events org_state$employees &lt;- simulate_risk_events(org_state$employees, org_state) # ... rest of step ... } 9.2.6 Step 6: Add Tests Create tests/test_risk_tolerance.R: library(testthat) library(data.table) # Source required files source(&quot;../core/agent.R&quot;) source(&quot;../core/organization.R&quot;) source(&quot;../core/interactions.R&quot;) test_that(&quot;Risk tolerance is properly initialized&quot;, { # Test applicant creation applicants &lt;- create_applicant_pool(n_applicants = 100) expect_true(&quot;risk_tolerance&quot; %in% names(applicants)) expect_equal(length(applicants$risk_tolerance), 100) expect_true(all(!is.na(applicants$risk_tolerance))) # Test distribution expect_true(abs(mean(applicants$risk_tolerance)) &lt; 0.2) expect_true(abs(sd(applicants$risk_tolerance) - 1) &lt; 0.2) }) test_that(&quot;Risk tolerance affects interactions&quot;, { # Create two agents with different risk tolerances agent1 &lt;- data.table( agent_id = &quot;test1&quot;, risk_tolerance = 2, openness = 0, conscientiousness = 0, extraversion = 0, agreeableness = 0, emotional_stability = 0, identity_category = &quot;A&quot; ) agent2 &lt;- data.table( agent_id = &quot;test2&quot;, risk_tolerance = -2, openness = 0, conscientiousness = 0, extraversion = 0, agreeableness = 0, emotional_stability = 0, identity_category = &quot;A&quot; ) # Test interaction satisfaction satisfaction &lt;- calculate_interaction_satisfaction(agent1, agent2) # Should be lower due to risk tolerance difference expect_true(satisfaction &lt; 0.7) }) test_that(&quot;Risk-based selection works correctly&quot;, { applicants &lt;- create_applicant_pool(n_applicants = 50) org_state &lt;- list( params = list(target_risk_level = 1.5), culture = list(risk_taking_culture = 0.5) ) evaluated &lt;- evaluate_applicants( applicants, org_state, selection_criteria = &quot;risk_tolerance&quot; ) # Check that selection scores favor applicants close to target best_applicant &lt;- evaluated[which.max(selection_score)] expect_true(abs(best_applicant$risk_tolerance - 1.5) &lt; 1) }) test_that(&quot;Risk performance modifier calculates correctly&quot;, { # Test multiple risk levels low_risk &lt;- calculate_risk_performance_modifier(-2) high_risk &lt;- calculate_risk_performance_modifier(2) # High risk should have higher variance set.seed(123) low_risk_mods &lt;- replicate(1000, calculate_risk_performance_modifier(-2)) high_risk_mods &lt;- replicate(1000, calculate_risk_performance_modifier(2)) expect_true(var(high_risk_mods) &gt; var(low_risk_mods)) }) 9.2.7 Step 7: Update Documentation Add to docs/06-api-reference.Rmd: ### Agent Attributes Agents in the simulation have the following attributes: - **risk_tolerance**: Normal(0, 1) - Propensity for risk-taking behavior - Values &gt; 1: Risk-seeking individuals - Values &lt; -1: Risk-averse individuals - Affects performance variability and interaction satisfaction 9.3 Code Flow Walkthrough 9.3.1 Simulation Step Trace Here’s a detailed trace through one simulation step: # STEP 1: Main loop calls run_simulation_step() run_asa_simulation() └── for (step in 1:n_steps) └── run_simulation_step(org_state, step, params) # STEP 2: Check for hiring needs run_simulation_step() ├── if (step %% params$hiring_frequency == 0) │ └── perform_hiring_round() │ ├── create_applicant_pool() │ ├── calculate_org_attractiveness() │ ├── evaluate_applicants() │ └── hire_applicants() │ # STEP 3: Process interactions ├── simulate_interactions() │ ├── sample_interaction_pairs() │ ├── for each pair: │ │ └── calculate_interaction_satisfaction() │ └── update_satisfaction_history() │ # STEP 4: Calculate turnover ├── process_turnover() │ ├── calculate_turnover_probability() │ ├── identify_leavers() │ └── remove_employees() │ # STEP 5: Update metrics └── update_org_metrics() ├── calculate_diversity_index() ├── calculate_mean_satisfaction() ├── calculate_performance_metrics() └── store_step_history() 9.3.2 Data Flow Diagram ┌─────────────────┐ ┌──────────────────┐ ┌─────────────────┐ │ Applicant Pool │────▶│ Organization │────▶│ History/Metrics │ └─────────────────┘ └──────────────────┘ └─────────────────┘ │ │ │ │ ▼ │ │ ┌──────────────────┐ │ │ │ Employees │ │ │ └──────────────────┘ │ │ │ │ │ ▼ │ │ ┌──────────────────┐ │ └──────────────▶│ Interactions │──────────────┘ └──────────────────┘ 9.3.3 Key Functions and Responsibilities Module Function Responsibility engine.R run_asa_simulation() Main entry point, orchestrates simulation engine.R run_simulation_step() Executes one time step agent.R create_applicant_pool() Generates new applicants organization.R initialize_organization() Sets up initial state hiring.R perform_hiring_round() Manages hiring process interactions.R simulate_interactions() Handles social dynamics turnover.R process_turnover() Manages employee departures 9.4 Testing Philosophy 9.4.1 Types of Tests Unit Tests: Test individual functions in isolation test_that(&quot;Diversity index calculates correctly&quot;, { employees &lt;- data.table( identity_category = c(&quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;, &quot;C&quot;) ) blau_index &lt;- calculate_diversity_index(employees, method = &quot;blau&quot;) expect_equal(blau_index, 0.64) # 1 - (0.4^2 + 0.4^2 + 0.2^2) }) Integration Tests: Test component interactions test_that(&quot;Hiring process integrates correctly&quot;, { org_state &lt;- initialize_organization(size = 10) initial_size &lt;- nrow(org_state$employees) org_state &lt;- perform_hiring_round(org_state, n_to_hire = 5) expect_equal(nrow(org_state$employees), initial_size + 5) expect_true(all(org_state$employees$hire_time &gt;= 0)) }) Regression Tests: Ensure changes don’t break existing functionality test_that(&quot;Simulation produces consistent results&quot;, { set.seed(12345) sim1 &lt;- run_asa_simulation(n_steps = 10, initial_size = 20) set.seed(12345) sim2 &lt;- run_asa_simulation(n_steps = 10, initial_size = 20) expect_identical(sim1$metrics, sim2$metrics) }) 9.4.2 Writing Good Tests Follow the AAA pattern: test_that(&quot;Employee satisfaction updates correctly&quot;, { # ARRANGE - Set up test data employee &lt;- data.table( agent_id = &quot;emp_001&quot;, satisfaction = 0, satisfaction_history = list(numeric(0)) ) # ACT - Execute the function updated_employee &lt;- update_satisfaction(employee, new_satisfaction = 0.7) # ASSERT - Check results expect_equal(updated_employee$satisfaction, 0.7) expect_length(updated_employee$satisfaction_history[[1]], 1) expect_equal(updated_employee$satisfaction_history[[1]][1], 0.7) }) 9.4.3 Test Coverage Expectations Core functions: 100% coverage required Utility functions: 90% coverage minimum Edge cases: Must test boundary conditions Error handling: Test invalid inputs Check coverage with: library(covr) cov &lt;- package_coverage() report(cov) 9.4.4 Running the Test Suite # Run all tests with detailed output testthat::test_dir(&quot;tests/&quot;, reporter = &quot;progress&quot;) # Run tests for a specific module testthat::test_file(&quot;tests/test_hiring.R&quot;) # Run tests matching a pattern testthat::test_dir(&quot;tests/&quot;, filter = &quot;diversity&quot;) # Run with coverage report covr::report(covr::package_coverage()) 9.5 Development Best Practices 9.5.1 R Coding Standards Function naming: Use descriptive verb_noun format # Good calculate_diversity_index() update_employee_satisfaction() # Avoid divIndex() empSatUpd() Variable naming: Use snake_case for variables # Good employee_count &lt;- nrow(employees) mean_satisfaction &lt;- mean(employees$satisfaction) # Avoid employeeCount &lt;- nrow(employees) meanSat &lt;- mean(employees$satisfaction) Function documentation: Use roxygen2 format #&#39; Calculate organization&#39;s cultural distance from target #&#39; #&#39; @param org_culture Current organizational culture (list) #&#39; @param target_culture Target cultural values (list) #&#39; @param weights Optional weights for culture dimensions #&#39; @return Numeric distance score (0 = identical, higher = more different) #&#39; @examples #&#39; culture &lt;- list(innovation = 0.7, stability = 0.3) #&#39; target &lt;- list(innovation = 0.9, stability = 0.1) #&#39; calculate_cultural_distance(culture, target) calculate_cultural_distance &lt;- function(org_culture, target_culture, weights = NULL) { # Implementation } 9.5.2 Using data.table Effectively Reference semantics: Use := for in-place updates # Efficient - modifies in place employees[, satisfaction := satisfaction + 0.1] # Inefficient - creates copy employees$satisfaction &lt;- employees$satisfaction + 0.1 Group operations: Use by for grouped calculations # Calculate mean satisfaction by identity category employees[, .( mean_satisfaction = mean(satisfaction), count = .N ), by = identity_category] Keys for performance: Set keys on frequently joined columns setkey(employees, agent_id) setkey(interactions, agent1_id, agent2_id) Chaining operations: Use data.table chaining employees[ tenure &gt; 12 ][ , satisfaction_rank := rank(-satisfaction) ][ satisfaction_rank &lt;= 10 ] 9.5.3 Performance Considerations Preallocate memory: # Good - preallocate results &lt;- vector(&quot;numeric&quot;, n_steps) for (i in 1:n_steps) { results[i] &lt;- calculate_metric(i) } # Avoid - growing vectors results &lt;- c() for (i in 1:n_steps) { results &lt;- c(results, calculate_metric(i)) } Vectorize operations: # Good - vectorized employees[, performance := conscientiousness * 0.3 + emotional_stability * 0.2 + satisfaction * 0.5] # Avoid - row-by-row for (i in 1:nrow(employees)) { employees$performance[i] &lt;- employees$conscientiousness[i] * 0.3 + employees$emotional_stability[i] * 0.2 + employees$satisfaction[i] * 0.5 } Profile bottlenecks: library(profvis) profvis({ sim_results &lt;- run_asa_simulation( n_steps = 100, initial_size = 200 ) }) 9.5.4 Documentation Standards Function-level documentation: Every exported function needs roxygen2 docs Inline comments: Explain “why”, not “what” # Good: Explains reasoning # Use Blau index for categorical diversity as it handles # multiple categories better than simple proportion variance diversity &lt;- calculate_blau_index(categories) # Avoid: States the obvious # Calculate diversity diversity &lt;- calculate_blau_index(categories) Complex algorithms: Add block comments # The Attraction-Selection-Attrition process: # 1. ATTRACTION: Applicants evaluate org attractiveness based on # visible diversity and cultural signals # 2. SELECTION: Organization evaluates applicants using # configured criteria (conscientiousness, fit, etc.) # 3. ATTRITION: Employees leave based on satisfaction levels # accumulated through interactions 9.6 Git Workflow 9.6.1 Branching Strategy We use Git Flow: main └── develop ├── feature/add-risk-tolerance ├── feature/improve-performance ├── bugfix/hiring-calculation └── hotfix/critical-error 9.6.2 Branch Naming Conventions Features: feature/descriptive-name Bugfixes: bugfix/issue-description Hotfixes: hotfix/critical-issue Releases: release/version-number 9.6.3 Commit Message Conventions Follow the conventional commits format: type(scope): subject body footer Examples: feat(hiring): add risk-based selection criteria - Implement risk_tolerance attribute for agents - Add selection strategy based on risk preference - Update tests for new functionality Closes #123 fix(turnover): correct satisfaction threshold calculation The previous implementation used &gt;= instead of &gt;, causing employees with exactly threshold satisfaction to leave. perf(interactions): optimize interaction sampling - Replace nested loops with vectorized operations - Add index on interaction history - Reduces step time by ~40% for large organizations docs(api): update hiring function documentation - Add examples for new selection criteria - Clarify parameter descriptions - Fix typos in return value docs 9.6.4 Pull Request Process Create feature branch: git checkout develop git pull origin develop git checkout -b feature/your-feature-name Make changes and commit: git add -A git commit -m &quot;feat(module): description&quot; Keep branch updated: git checkout develop git pull origin develop git checkout feature/your-feature-name git rebase develop Push and create PR: git push origin feature/your-feature-name PR description template: ## Description Brief description of changes ## Type of Change - [ ] Bug fix - [ ] New feature - [ ] Breaking change - [ ] Documentation update ## Testing - [ ] Unit tests pass - [ ] Integration tests pass - [ ] Manual testing completed ## Checklist - [ ] Code follows style guidelines - [ ] Self-review completed - [ ] Comments added for complex sections - [ ] Documentation updated - [ ] No warnings in R CMD check 9.6.5 Code Review Guidelines For Reviewers: Check for: Correctness of implementation Test coverage Performance implications Documentation completeness Code style consistency Provide constructive feedback: # Good feedback &quot;Consider using data.table&#39;s `.SDcols` here for better performance when selecting columns. Example: `DT[, .SD, .SDcols = patterns(&quot;^metric_&quot;)]`&quot; # Avoid &quot;This is inefficient&quot; For Authors: Respond to all comments Mark resolved conversations Request re-review after changes 9.7 Common Development Tasks 9.7.1 Adding New Parameters Update parameter list in simulation/engine.R: default_params &lt;- list( # ... existing parameters ... # Social network parameters network_density = 0.1, # NEW: How connected the network is network_clustering = 0.3, # NEW: Tendency to form cliques weak_tie_strength = 0.5 # NEW: Influence of weak ties ) Add validation in parameter checking: validate_parameters &lt;- function(params) { assert_number(params$network_density, lower = 0, upper = 1) assert_number(params$network_clustering, lower = 0, upper = 1) assert_number(params$weak_tie_strength, lower = 0, upper = 1) # ... existing validations ... } Implement parameter effects: # In simulate_interactions() n_interactions &lt;- ceiling( params$n_interactions_per_step * params$network_density ) Document in user guide (docs/04-user-guide.Rmd): ### Network Parameters - `network_density`: Controls how many interactions occur (0-1) - `network_clustering`: Tendency to form cliques (0-1) - `weak_tie_strength`: Influence of distant connections (0-1) 9.7.2 Creating New Metrics Define calculation function: #&#39; Calculate network centralization #&#39; #&#39; @param interactions data.table of interaction records #&#39; @param employees data.table of current employees #&#39; @return Numeric centralization score (0-1) calculate_network_centralization &lt;- function(interactions, employees) { # Count interactions per employee degree_dist &lt;- interactions[ agent1_id %in% employees$agent_id | agent2_id %in% employees$agent_id ][, .( in_degree = sum(agent2_id == agent_id), out_degree = sum(agent1_id == agent_id) ), by = agent_id] # Calculate centralization (Freeman&#39;s formula) max_degree &lt;- max(degree_dist$in_degree + degree_dist$out_degree) sum_diff &lt;- sum(max_degree - (degree_dist$in_degree + degree_dist$out_degree)) max_sum_diff &lt;- (nrow(employees) - 1) * (nrow(employees) - 2) centralization &lt;- sum_diff / max_sum_diff return(centralization) } Integrate into simulation: # In update_org_metrics() update_org_metrics &lt;- function(org_state, step) { # ... existing metrics ... # Calculate network centralization if (nrow(org_state$interaction_history) &gt; 0) { recent_interactions &lt;- org_state$interaction_history[ time &gt;= step - org_state$params$interaction_window ] org_state$metrics$network_centralization &lt;- c( org_state$metrics$network_centralization, calculate_network_centralization( recent_interactions, org_state$employees ) ) } return(org_state) } Add visualization: #&#39; Plot network centralization over time #&#39; #&#39; @param simulation_results Output from run_asa_simulation() #&#39; @return ggplot object plot_network_centralization &lt;- function(simulation_results) { metrics_df &lt;- data.frame( step = seq_along(simulation_results$metrics$network_centralization), centralization = simulation_results$metrics$network_centralization ) ggplot(metrics_df, aes(x = step, y = centralization)) + geom_line(color = &quot;darkblue&quot;, size = 1) + geom_smooth(method = &quot;loess&quot;, se = TRUE, alpha = 0.2) + labs( title = &quot;Network Centralization Over Time&quot;, x = &quot;Simulation Step&quot;, y = &quot;Centralization (0-1)&quot; ) + theme_minimal() } 9.7.3 Implementing New Selection Strategies Define strategy function: #&#39; Select applicants based on network potential #&#39; #&#39; @param applicants data.table of applicants #&#39; @param org_state Current organization state #&#39; @return data.table with selection_score column select_by_network_potential &lt;- function(applicants, org_state) { # Calculate potential bridge connections current_categories &lt;- org_state$employees[, .N, by = identity_category] applicants[, &#39;:=&#39;( # Favor applicants who can bridge underconnected groups bridge_potential = sapply(identity_category, function(cat) { cat_size &lt;- current_categories[identity_category == cat, N] if (is.na(cat_size)) cat_size &lt;- 0 # Higher score for smaller groups (more bridging potential) return(1 / (cat_size + 1)) }), # Also consider social traits social_skills = extraversion * 0.5 + agreeableness * 0.3 + openness * 0.2 )] # Combine into selection score applicants[, selection_score := bridge_potential * 0.6 + social_skills * 0.4] return(applicants) } Register strategy in hiring.R: evaluate_applicants &lt;- function(applicants, org_state, selection_criteria) { # ... existing criteria ... else if (selection_criteria == &quot;network_potential&quot;) { applicants &lt;- select_by_network_potential(applicants, org_state) } # ... rest of function ... } Add tests: test_that(&quot;Network potential selection works correctly&quot;, { # Create org with unbalanced categories org_state &lt;- list( employees = data.table( agent_id = paste0(&quot;emp_&quot;, 1:10), identity_category = c(rep(&quot;A&quot;, 7), rep(&quot;B&quot;, 2), &quot;C&quot;) ) ) # Create applicants applicants &lt;- data.table( agent_id = paste0(&quot;app_&quot;, 1:3), identity_category = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), extraversion = c(0, 0, 0), agreeableness = c(0, 0, 0), openness = c(0, 0, 0) ) # Apply selection result &lt;- select_by_network_potential(applicants, org_state) # Category C applicant should score highest (smallest group) expect_equal(which.max(result$selection_score), 3) }) 9.7.4 Adding Visualization Functions Create visualization function: #&#39; Create interactive satisfaction heatmap #&#39; #&#39; @param org_state Organization state with employees #&#39; @param step Current simulation step #&#39; @return plotly object create_satisfaction_heatmap &lt;- function(org_state, step = NULL) { # Prepare data satisfaction_matrix &lt;- dcast( org_state$interaction_history[ time == max(time) ][ , .(agent1_id, agent2_id, satisfaction) ], agent1_id ~ agent2_id, value.var = &quot;satisfaction&quot;, fill = NA ) # Convert to matrix sat_mat &lt;- as.matrix(satisfaction_matrix[, -1]) rownames(sat_mat) &lt;- satisfaction_matrix$agent1_id # Create heatmap plot_ly( z = sat_mat, x = colnames(sat_mat), y = rownames(sat_mat), type = &quot;heatmap&quot;, colorscale = &quot;RdBu&quot;, zmin = -1, zmax = 1, text = matrix( paste(&quot;From:&quot;, rep(rownames(sat_mat), ncol(sat_mat)), &quot;&lt;br&gt;To:&quot;, rep(colnames(sat_mat), each = nrow(sat_mat)), &quot;&lt;br&gt;Satisfaction:&quot;, round(as.vector(sat_mat), 2)), nrow = nrow(sat_mat) ), hoverinfo = &quot;text&quot; ) %&gt;% layout( title = paste(&quot;Interaction Satisfaction Matrix&quot;, ifelse(!is.null(step), paste(&quot;- Step&quot;, step), &quot;&quot;)), xaxis = list(title = &quot;Agent 2&quot;), yaxis = list(title = &quot;Agent 1&quot;) ) } Add to visualization suite: # In create_simulation_dashboard() create_simulation_dashboard &lt;- function(simulation_results) { # ... existing plots ... # Add satisfaction heatmap satisfaction_heat &lt;- create_satisfaction_heatmap( simulation_results$final_state, step = simulation_results$params$n_steps ) # Combine into dashboard subplot( diversity_plot, satisfaction_plot, satisfaction_heat, nrows = 2, shareX = FALSE, titleY = TRUE ) } 9.8 Debugging Tips 9.8.1 Common Errors and Solutions “object ‘column_name’ not found” # Problem: Column doesn&#39;t exist in data.table employees[, new_col := old_col * 2] # Error if old_col missing # Solution: Check column exists first if (&quot;old_col&quot; %in% names(employees)) { employees[, new_col := old_col * 2] } else { warning(&quot;Column &#39;old_col&#39; not found, skipping calculation&quot;) } “invalid subscript type ‘list’” # Problem: Using list column incorrectly employees[, mean(satisfaction_history)] # Error # Solution: Unlist or use sapply employees[, mean(unlist(satisfaction_history)), by = agent_id] Memory issues with large simulations # Problem: Storing full history exhausts memory # Solution: Implement rolling window storage store_history &lt;- function(history, new_data, max_size = 1000) { history &lt;- rbind(history, new_data) if (nrow(history) &gt; max_size) { history &lt;- history[-(1:(nrow(history) - max_size))] } return(history) } 9.8.2 Debugging Techniques for R Use browser() for interactive debugging: calculate_complex_metric &lt;- function(data) { # Some preparation processed &lt;- prepare_data(data) browser() # Execution stops here # Complex calculation result &lt;- complex_calculation(processed) return(result) } Add verbose logging: run_simulation_step &lt;- function(org_state, step, params) { if (params$verbose) { cat(sprintf(&quot;\\n=== Step %d ===\\n&quot;, step)) cat(sprintf(&quot;Employees: %d\\n&quot;, nrow(org_state$employees))) cat(sprintf(&quot;Mean satisfaction: %.3f\\n&quot;, mean(org_state$employees$satisfaction))) } # ... rest of function ... } Use trace() for non-invasive debugging: # Add debugging to existing function without modifying source trace(calculate_diversity_index, tracer = quote(print(paste(&quot;Input has&quot;, nrow(employees), &quot;rows&quot;)))) # Remove tracing untrace(calculate_diversity_index) Defensive programming with assertions: process_interactions &lt;- function(employees, interactions) { # Validate inputs assert_data_table(employees) assert_data_table(interactions) assert_subset(c(&quot;agent1_id&quot;, &quot;agent2_id&quot;), names(interactions)) # Check data integrity invalid_agents &lt;- setdiff( c(interactions$agent1_id, interactions$agent2_id), employees$agent_id ) if (length(invalid_agents) &gt; 0) { stop(sprintf(&quot;Invalid agent IDs in interactions: %s&quot;, paste(invalid_agents, collapse = &quot;, &quot;))) } # ... rest of function ... } 9.8.3 Performance Profiling Profile entire simulation: library(profvis) profvis({ results &lt;- run_asa_simulation( n_steps = 100, initial_size = 500, params = list( n_interactions_per_step = 20, verbose = FALSE ) ) }) Benchmark specific functions: library(microbenchmark) # Compare different diversity calculations employees &lt;- create_test_employees(1000) microbenchmark( blau = calculate_diversity_index(employees, &quot;blau&quot;), shannon = calculate_diversity_index(employees, &quot;shannon&quot;), custom = calculate_diversity_index(employees, &quot;custom&quot;), times = 100 ) Memory profiling: library(pryr) # Check object sizes object_size(org_state$employees) object_size(org_state$interaction_history) # Track memory usage mem_before &lt;- mem_used() results &lt;- run_asa_simulation(n_steps = 50) mem_after &lt;- mem_used() cat(sprintf(&quot;Memory used: %.2f MB\\n&quot;, (mem_after - mem_before) / 1024^2)) 9.8.4 Using Verbose Mode Effectively Implement tiered verbosity: # In parameters params$verbose_level &lt;- 2 # 0=silent, 1=basic, 2=detailed, 3=debug # In functions log_message &lt;- function(message, level = 1, current_level = params$verbose_level) { if (current_level &gt;= level) { cat(paste0(rep(&quot; &quot;, level - 1), message, &quot;\\n&quot;)) } } # Usage log_message(&quot;Starting simulation&quot;, level = 1) log_message(&quot;Initializing organization&quot;, level = 2) log_message(sprintf(&quot;Created %d employees&quot;, nrow(employees)), level = 3) Add progress bars for long operations: run_asa_simulation &lt;- function(n_steps, ..., show_progress = TRUE) { if (show_progress) { pb &lt;- txtProgressBar(min = 0, max = n_steps, style = 3) } for (step in 1:n_steps) { # ... simulation step ... if (show_progress) { setTxtProgressBar(pb, step) } } if (show_progress) { close(pb) } } 9.9 Summary This contributor’s guide provides a comprehensive walkthrough for developing and extending the ASA ABM v2 codebase. Key takeaways: Start small: Begin with simple features and gradually tackle more complex ones Test everything: Write tests before, during, and after implementation Document as you go: Future you (and other contributors) will thank you Profile early: Don’t wait until performance becomes a problem Ask questions: The community is here to help Remember that good code is not just code that works—it’s code that others can understand, maintain, and build upon. Happy contributing! 9.10 Additional Resources data.table Documentation testthat Testing Framework R Performance Optimization Git Flow Workflow "],["quick-ref.html", "Chapter 10 ASA ABM v2 Quick Reference 10.1 Quick Start 10.2 Parameter Reference 10.3 Key Functions 10.4 Data Structures 10.5 Common Code Patterns 10.6 Visualization Recipes 10.7 Performance Tips 10.8 Debugging Commands", " Chapter 10 ASA ABM v2 Quick Reference 10.1 Quick Start # Load and run simulation source(&quot;simulation/engine.R&quot;) results &lt;- run_asa_simulation(n_steps = 260, initial_size = 100) # View results tail(results$metrics, 10) # Recent metrics summary(results$final_organization) # Final state # Quick visualization library(ggplot2) ggplot(results$metrics, aes(x = time_step, y = organization_size)) + geom_line() 10.2 Parameter Reference Parameter Type Default Range/Values Description n_steps int 260 1-∞ Simulation duration initial_size int 100 1-10000 Starting employees growth_rate num 0.01 0-1 Hiring growth per cycle hiring_frequency int 12 1-52 Steps between hiring selection_criteria chr “conscientiousness” “conscientiousness”, “fit”, “random” Hiring strategy n_interactions_per_step int 5 1-100 Interactions per agent interaction_window int 10 1-52 Memory for interactions turnover_threshold num -10 -20-0 Satisfaction exit level turnover_type chr “threshold” “threshold”, “probabilistic” Attrition method base_turnover_rate num 0.05 0-1 Base attrition probability n_new_applicants int 50 1-1000 Applicants per cycle applicant_attraction_threshold num -0.5 -5-5 Min attraction to apply max_application_time int 12 1-52 Applicant pool timeout diversity_metric chr “blau” “blau”, “shannon” Diversity calculation identity_categories vec c(“A”,“B”,“C”,“D”,“E”) Any Identity types 10.3 Key Functions 10.3.1 Core Functions # Organization Management create_organization(n_agents, identity_categories) get_organization_size(org) get_active_employees(org) calculate_blau_index(categories) calculate_shannon_diversity(categories) # Agent Creation create_applicant_pool(n_applicants, identity_categories) calculate_attraction(agents, org_diversity, diversity_metric) create_agent(identity_category) # Simulation Engine run_asa_simulation(n_steps, initial_size, params, verbose) execute_interactions_vectorized(org, interactions, step, n_interactions) update_satisfaction_vectorized(org, interactions, window, diversity_metric) execute_turnover(org, threshold, current_time) execute_hiring(org, applicant_pool, selection_criteria, n_positions) 10.3.2 Analysis Functions # Metrics calculate_personality_averages(org) calculate_step_metrics(org, step) get_interaction_summary(interactions) # Utilities age_applicant_pool(pool, max_age) recruit_applicants(pool, n_new) applicants_to_employees(applicants, hire_date) 10.4 Data Structures 10.4.1 Organization Table org &lt;- data.table( agent_id # chr: Unique ID &quot;agent_XXX&quot; identity_category # chr: &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, or &quot;E&quot; openness # num: 0-1 (Big Five trait) conscientiousness # num: 0-1 (Big Five trait) extraversion # num: 0-1 (Big Five trait) agreeableness # num: 0-1 (Big Five trait) emotional_stability # num: 0-1 (Big Five trait) homophily_preference # num: 0-1 (similarity preference) diversity_preference # num: 0-1 (diversity preference) attraction # num: -∞-∞ (to organization) satisfaction # num: -∞-∞ (current satisfaction) tenure # int: Steps in organization hire_date # int: Step when hired is_active # lgl: TRUE if employed ) 10.4.2 Metrics Output metrics &lt;- data.table( time_step # int: Simulation step organization_size # int: Active employees prop_A - prop_E # num: Identity proportions shannon_diversity # num: Shannon entropy blau_index # num: Blau&#39;s index avg_satisfaction # num: Mean satisfaction sd_satisfaction # num: SD satisfaction avg_openness # num: Mean trait value sd_openness # num: SD trait value # ... other personality traits ) 10.5 Common Code Patterns 10.5.1 Running Multiple Scenarios scenarios &lt;- list( high_growth = list(growth_rate = 0.1), high_turnover = list(turnover_threshold = -5), diverse_hiring = list(selection_criteria = &quot;random&quot;) ) results &lt;- lapply(names(scenarios), function(name) { run_asa_simulation(params = scenarios[[name]]) }) 10.5.2 Batch Analysis # Extract final metrics final_metrics &lt;- lapply(results, function(r) { tail(r$metrics, 1) }) comparison &lt;- rbindlist(final_metrics, idcol = &quot;scenario&quot;) # Time series comparison all_metrics &lt;- lapply(seq_along(results), function(i) { results[[i]]$metrics[, scenario := names(scenarios)[i]] }) combined &lt;- rbindlist(all_metrics) 10.5.3 Custom Metrics # Add to organization org[, network_centrality := degree_centrality / (.N - 1)] org[, cultural_distance := abs(conscientiousness - mean(conscientiousness))] # Calculate in simulation custom_metric &lt;- org[is_active == TRUE, .(cultural_variance = var(conscientiousness), satisfaction_gini = ineq::Gini(satisfaction))] 10.6 Visualization Recipes 10.6.1 Time Series with Phases ggplot(metrics, aes(x = time_step)) + geom_line(aes(y = organization_size), size = 1.2) + geom_vline(xintercept = c(50, 100, 150), linetype = &quot;dashed&quot;, alpha = 0.5) + annotate(&quot;rect&quot;, xmin = 0, xmax = 50, ymin = -Inf, ymax = Inf, alpha = 0.1, fill = &quot;blue&quot;) + labs(title = &quot;Organizational Growth&quot;, x = &quot;Time&quot;, y = &quot;Size&quot;) + theme_minimal() 10.6.2 Multi-Metric Dashboard library(patchwork) p1 &lt;- ggplot(metrics, aes(time_step, organization_size)) + geom_line(color = &quot;blue&quot;) p2 &lt;- ggplot(metrics, aes(time_step, blau_index)) + geom_line(color = &quot;red&quot;) p3 &lt;- ggplot(metrics, aes(time_step, avg_satisfaction)) + geom_line(color = &quot;green&quot;) p4 &lt;- ggplot(metrics, aes(time_step, avg_conscientiousness)) + geom_line(color = &quot;purple&quot;) (p1 + p2) / (p3 + p4) + plot_annotation(title = &quot;Simulation Dashboard&quot;) 10.6.3 Distribution Comparison # Compare initial vs final bind_rows( org[hire_date &lt;= 10, .(phase = &quot;Initial&quot;, satisfaction)], org[is_active == TRUE, .(phase = &quot;Final&quot;, satisfaction)] ) %&gt;% ggplot(aes(x = satisfaction, fill = phase)) + geom_density(alpha = 0.6) + scale_fill_manual(values = c(&quot;Initial&quot; = &quot;blue&quot;, &quot;Final&quot; = &quot;red&quot;)) 10.7 Performance Tips Vectorize Everything: Use data.table operations, not loops Pre-allocate Memory: vector(\"list\", n_steps) for results Selective Updates: Use := for in-place modifications Index Key Columns: setkey(org, agent_id) for fast lookups Avoid Copying: Pass by reference when possible Profile Code: Use system.time() and profvis::profvis() Batch Operations: Group similar calculations Limit Snapshots: Store only necessary time points 10.8 Debugging Commands 10.8.1 Basic Debugging # Check data structure str(org) summary(org[is_active == TRUE]) table(org$identity_category) # Trace execution debug(run_asa_simulation) browser() # Set breakpoint trace(execute_hiring, tracer = browser) # Verbose output results &lt;- run_asa_simulation(verbose = TRUE) 10.8.2 Data Validation # Check for NAs org[, lapply(.SD, function(x) sum(is.na(x)))] # Verify constraints stopifnot(all(org$satisfaction &gt; -100)) stopifnot(all(org$tenure &gt;= 0)) # Test single step test_org &lt;- org[1:10] # Small subset test_result &lt;- execute_interactions_vectorized( test_org, interactions, step = 1, n_interactions = 2 ) 10.8.3 Performance Profiling # Time specific operations system.time({ for(i in 1:100) { calculate_blau_index(org$identity_category) } }) # Memory usage pryr::object_size(org) gc() # Garbage collection # Full profiling profvis::profvis({ run_asa_simulation(n_steps = 50) }) ASA ABM v2 - Agent-Based Model for Attraction-Selection-Attrition "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
